{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian NN\n",
    "\n",
    "TODOs\n",
    "- bayesian uncertainty: need to implement a BNN \n",
    "- then test with curriculum\n",
    "    \n",
    "    \n",
    "\n",
    "# Useful Links\n",
    "- cifar ex https://github.com/tensorflow/probability/blob/80cc5cb33dfe04cb998bfe27ad3680a7a116d8b1/tensorflow_probability/examples/cifar10_bnn.py\n",
    "- uses resnet https://github.com/tensorflow/probability/blob/80cc5cb33dfe04cb998bfe27ad3680a7a116d8b1/tensorflow_probability/examples/models/bayesian_resnet.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0724 11:36:52.403292 140218034444032 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "W0724 11:36:52.462412 140218034444032 __init__.py:335] Limited tf.summary API due to missing TensorBoard installation.\n",
      "/data/miniconda3/envs/EpitomeEnv_c76/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n",
      "W0724 11:36:57.660215 140218034444032 __init__.py:308] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from epitome.constants import *\n",
    "from epitome.models import *\n",
    "from epitome.generators import *\n",
    "from epitome.functions import *\n",
    "from epitome.viz import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "assert(tf.executing_eagerly())\n",
    "import tensorflow_probability as tfp\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919, 2200000) (919, 4000) (919, 227512)\n"
     ]
    }
   ],
   "source": [
    "# load in user paths\n",
    "# TODO: make a config file with data_path (downloaded from bin/download_deepsea_data.py) \n",
    "# and feature_name_file (at data/feature_name)\n",
    "# My config.yml looks like:\n",
    "# data_path: /data/akmorrow/epitome_data/numpy_data/\n",
    "# feature_name_file: /home/eecs/akmorrow/epitome/data/feature_name\n",
    "\n",
    "with open('/home/eecs/akmorrow/epitome/config.yml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "train_data, valid_data, test_data = load_deepsea_label_data(config[\"data_path\"])\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "print(data[Dataset.TRAIN].shape, data[Dataset.VALID].shape, data[Dataset.TEST].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eligible_assays = ['DNase',\n",
    " 'p300',\n",
    " 'c-Myc',\n",
    " 'ZNF274',\n",
    " 'USF2',\n",
    " 'TR4',\n",
    " 'TBP',\n",
    " 'TAF1',\n",
    " 'SMC3',\n",
    " 'Rad21',\n",
    " 'RFX5',\n",
    " 'Pol2(phosphoS2)',\n",
    " 'Pol2',\n",
    " 'Nrf1',\n",
    " 'NRSF',\n",
    " 'Mxi1',\n",
    " 'Max',\n",
    " 'MAZ',\n",
    " 'JunD',\n",
    " 'GABP',\n",
    " 'EZH2',\n",
    " 'CTCF',\n",
    " 'COREST',\n",
    " 'CHD2',\n",
    " 'CEBPB']\n",
    "\n",
    "matrix, cellmap, assaymap = get_assays_from_feature_file(eligible_assays = eligible_assays,\n",
    "                                  eligible_cells = None, min_cells_per_assay =5, \n",
    "                                                         min_assays_per_cell=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f85d81655c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nv_assaymap = {v: k for k, v in assaymap.items()}\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(np.arange(len(assaymap)), rotation = 90)\n",
    "ax.set_xticklabels(assaymap.keys())\n",
    "plt.yticks(np.arange(len(cellmap)))\n",
    "ax.set_yticklabels(cellmap.keys())\n",
    "\n",
    "plt.imshow(matrix!=Label.UNK.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(data, \n",
    "                 label_cell_types,  # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix,\n",
    "                 assaymap,\n",
    "                 cellmap,\n",
    "                 radii,\n",
    "                 **kwargs):\n",
    "    \n",
    "    # AM 5/20/2019. This is enforcing exclusive DNase bins and will make \n",
    "    # interpretation of DNase weights easier. It does not add performance benefit\n",
    "    # over inclusive bins, which was used in the original model.\n",
    "    exclusive = True\n",
    "\n",
    "    \"\"\"\n",
    "    Takes Deepsea data and calculates distance metrics from cell types whose locations\n",
    "    are specified by label_cell_indices, and the other cell types in the set. Label space is only one cell type.\n",
    "     TODO AM 3/7/2019\n",
    "    :param data: dictionary of matrices. Should have keys x and y. x contains n by 1000 rows. y contains n by 919 labels.\n",
    "    :param label_cell_types: list of cell types to be rotated through and used as labels (subset of eval_cell_types)\n",
    "    :param eval_cell_types: list of cell types to be used in evaluation (includes label_cell_types)\n",
    "    :param matrix: matrix of celltype, assay positions\n",
    "    :param assaymap: map of column assay positions in matrix\n",
    "    :param cellmap: map of row cell type positions in matrix\n",
    "    :param radii: radii to compute dnase distances from\n",
    "    :param kwargs: kargs\n",
    "\n",
    "    :returns: generator of data with three elements:\n",
    "        1. record features\n",
    "        2. record labels for a given cell type\n",
    "        3. 0/1 mask of labels that have validation data. For example, if this record is for celltype A549,\n",
    "        and A549 does not have data for ATF3, there will be a 0 in the position corresponding to the label space.\n",
    "    \"\"\"\n",
    "\n",
    "    # Running in TRAIN, VALID, or TEST?    \n",
    "    mode = kwargs.get(\"mode\")\n",
    "    # specifies the indices to generate records.\n",
    "    # can be used for debug purposes, or to evaluate\n",
    "    # only specific regions in a vector\n",
    "    # TODO AM 4/17/2019: move this to an actual parameter\n",
    "    indices = kwargs.get(\"indices\")\n",
    "    \n",
    "    if (not isinstance(indices, np.ndarray) and not isinstance(indices, list)):\n",
    "        indices = range(0, data.shape[-1]) # if not defined, set to all points\n",
    "    \n",
    "    if (not isinstance(mode, Dataset)):\n",
    "        raise ValueError(\"mode is not a Dataset enum\")\n",
    "        \n",
    "    if (mode == Dataset.RUNTIME):\n",
    "        label_cell_types = [\"PLACEHOLDER_CELL\"]\n",
    "        dnase_vector = kwargs.get(\"dnase_vector\")\n",
    "        random_cell = list(cellmap)[0] # placeholder to get label vector length\n",
    "        \n",
    "    print(\"using %s as labels for mode %s\" % (label_cell_types, mode))\n",
    "    \n",
    "    # string of radii for meta data labeling\n",
    "    radii_str = list(map(lambda x: \"DNASE_RADII_%i\" % x, radii))\n",
    "        \n",
    "    if (mode == Dataset.TEST or mode == Dataset.RUNTIME):\n",
    "        # Drop cell types with the least information (TODO AM 4/1/2019 this could do something smarter)\n",
    "        \n",
    "        # make dictionary of eval_cell_type: assay count and sort in decreasing order\n",
    "        tmp = matrix.copy()\n",
    "        tmp[tmp>= 0] = 1\n",
    "        tmp[tmp== -1] = 0\n",
    "        sums = np.sum(tmp, axis = 1)\n",
    "        cell_assay_counts = zip(list(cellmap), sums)\n",
    "        cell_assay_counts = sorted(cell_assay_counts, key = lambda x: x[1])\n",
    "        # filter by eval_cell_types\n",
    "        cell_assay_counts = list(filter(lambda x: x[0] in eval_cell_types, cell_assay_counts))\n",
    "        \n",
    "        # remove cell types with smallest number of factors\n",
    "        eval_cell_types = eval_cell_types.copy()\n",
    "        [eval_cell_types.remove(i[0]) for i in cell_assay_counts[0:len(label_cell_types)]]\n",
    "        del tmp\n",
    "        del cell_assay_counts\n",
    "        \n",
    "        \n",
    "    def g():\n",
    "        for i in indices: # for all records specified\n",
    "            for (cell) in label_cell_types: # for all cell types to be used in labels\n",
    "                dnases = [] \n",
    "                dnases_double_positive = []\n",
    "                dnases_agreement = []\n",
    "                \n",
    "                # cells to be featurized\n",
    "                feature_cells = eval_cell_types.copy()\n",
    "                \n",
    "                # try to remove cell if it is in the possible list of feature cell types\n",
    "                try:\n",
    "                    feature_cells.remove(cell) \n",
    "                except ValueError:\n",
    "                    pass  # do nothing!\n",
    "                                \n",
    "                # features from all remaining cells not in label set\n",
    "                feature_cell_indices_list = list(map(lambda c: get_y_indices_for_cell(matrix, cellmap, c), \n",
    "                                                     feature_cells))\n",
    "                feature_cell_indices = np.array(feature_cell_indices_list).flatten()\n",
    "                \n",
    "                # labels for this cell\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    label_cell_indices = get_y_indices_for_cell(matrix, cellmap, cell)\n",
    "                    label_cell_indices_no_dnase = np.delete(label_cell_indices, [0])\n",
    "\n",
    "                    # Copy assay_index_no_dnase and turn into mask of 0/1 for whether data for this cell type for\n",
    "                    # a given label is available.\n",
    "                    assay_mask = np.copy(label_cell_indices_no_dnase)\n",
    "                    assay_mask[assay_mask == -1] = 0\n",
    "                    assay_mask[assay_mask > 0] = 1\n",
    "                    \n",
    "                else:\n",
    "                    label_count = len(get_y_indices_for_cell(matrix, cellmap, random_cell))-1\n",
    "                    \n",
    "                    # Mask and labels are all 0's because labels are missing during runtime\n",
    "                    garbage_labels = assay_mask = np.zeros(label_count)\n",
    "\n",
    "                # get dnase indices for cell types that are going to be features\n",
    "                dnase_indices = np.array([x[0] for x in feature_cell_indices_list])\n",
    "                \n",
    "                for r, radius in enumerate(radii):\n",
    "                    \n",
    "                    min_radius = max(0, i - radius + 1)\n",
    "                    max_radius = min(i+radius, data.shape[1])\n",
    "                    \n",
    "                    # if exclusive == True, then do not featurize chromatin regions\n",
    "                    # that were considered in smaller radii\n",
    "                    if (exclusive and r != 0):\n",
    "                        radius_range_1 = np.arange(min_radius, max(0, i - radii[r-1]+1))\n",
    "                        radius_range_2 = np.arange(i+radii[r-1], max_radius)\n",
    "                        \n",
    "                        radius_range = np.concatenate([radius_range_1, radius_range_2])\n",
    "                    else:\n",
    "                        \n",
    "                        radius_range = np.arange(min_radius, max_radius)\n",
    "                        \n",
    "                        \n",
    "                    ####################################################################\n",
    "                    \n",
    "                    # use DNase vector, if it is provided\n",
    "                    if (mode == Dataset.RUNTIME):\n",
    "\n",
    "                        # within the radius, fraction of places where they are both 1\n",
    "                        dnase_double_positive = np.average(data[dnase_indices[:,None],radius_range]*\n",
    "                                                 dnase_vector[radius_range], axis=1)\n",
    "\n",
    "                        # within the radius, fraction of places where they are both equal (0 or 1)\n",
    "                        dnase_agreement = np.average(data[dnase_indices[:,None],radius_range]==\n",
    "                                                 dnase_vector[radius_range], axis=1)\n",
    "\n",
    "                    else:\n",
    "                        # within the radius, fraction of places where they are both 1\n",
    "                        # label_cell_index[0] == DNase location for specific cell type\n",
    "                        dnase_double_positive = np.average(data[dnase_indices[:,None],radius_range]*\n",
    "                                                 data[label_cell_indices[0],radius_range], axis=1)\n",
    "\n",
    "                        # within the radius, fraction of places where they are both equal (0 or 1)\n",
    "                        dnase_agreement = np.average(data[dnase_indices[:,None],radius_range]==\n",
    "                                                 data[label_cell_indices[0],radius_range], axis=1)\n",
    "                        \n",
    "                    dnases_double_positive.extend(dnase_double_positive)\n",
    "                    dnases_agreement.extend(dnase_agreement)\n",
    "                        \n",
    "                # rehape agreement DNase to Radii by feature_cells\n",
    "                dnases_agreement_reshaped = np.array(dnases_agreement).reshape([len(radii), len(feature_cells)])\n",
    "                dnases_double_positive_reshaped = np.array(dnases_double_positive).reshape([len(radii), len(feature_cells)])\n",
    "                dnase_means = np.mean(dnases_agreement_reshaped, axis = 0)\n",
    "\n",
    "                ######### reorder cells by similarity ################\n",
    "                ## This was added 5/30/2019. It seems to *maybe help \n",
    "                ## a little bit on cell types not seen in the model.\n",
    "                ## This makes sense because cell types are now ordered\n",
    "                ## by similarity and keep some spacial positioning \n",
    "                ## based on the similarity to the new cell. \n",
    "                best_indices = (-dnase_means).argsort()\n",
    "\n",
    "                dnases.extend(dnases_double_positive_reshaped[:,best_indices].flatten())\n",
    "                dnases.extend(dnases_agreement_reshaped[:,best_indices].flatten())\n",
    "\n",
    "                feature_cell_indices = feature_cell_indices.reshape([len(feature_cells), len(assaymap)])[best_indices,:].flatten()\n",
    "                ######## End reorder #################################                                                   \n",
    "                                                                        \n",
    "                                                                        \n",
    "                # Extract features\n",
    "                features = data[feature_cell_indices,i]\n",
    "                \n",
    "                # concatenate features and DNases\n",
    "                x_data = np.concatenate([features, dnases])\n",
    "                \n",
    "                # mask for x_data. 0 = do not mask, 1 = mask.\n",
    "                x_mask = np.zeros(x_data.shape[0])\n",
    "                x_mask[np.where(feature_cell_indices == -1)[0]] = True # assign mask to missing features\n",
    "\n",
    "                # There can be NaNs in the DNases for edge cases (when the radii extends past the end of the chr).\n",
    "                # Mask these values in the first row of tmp\n",
    "                x_mask[np.where(np.isnan(x_data))[0]] = True # assign mask to missing DNase values\n",
    "                x_data[np.where(x_mask == True)[0]] = 0 # set all UNKs to 0\n",
    "                \n",
    "                # mask x data by which factors are available for a cell type\n",
    "                x_data_masked = np.vstack([x_mask, x_data]) # top row 0 = mask, bottom row 1 = data\n",
    "                        \n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    labels = data[label_cell_indices_no_dnase,i]\n",
    "\n",
    "                else: # used when just predicting\n",
    "                    # The features going into the example.\n",
    "                    labels = garbage_labels # all 0's\n",
    "                    \n",
    "                yield (x_data, labels, assay_mask)\n",
    "\n",
    "    return g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 16:35:32.596759 140218034444032 <ipython-input-176-d535bd998b52>:173] Starting Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval cell types ['SK-N-SH_RA', 'NB4', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549']\n",
      "using ['SK-N-SH_RA', 'NB4', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH_RA', 'NB4', 'MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'HUVEC', 'H1-hESC', 'GM12892', 'GM12891', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "using [] as labels for mode Dataset.TEST\n",
      "Error: no data, local variable 'x' referenced before assignment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 16:35:37.669785 140218034444032 <ipython-input-176-d535bd998b52>:198] 0\n",
      "I0724 16:37:00.650697 140218034444032 <ipython-input-176-d535bd998b52>:198] 1000\n",
      "I0724 16:38:23.116771 140218034444032 <ipython-input-176-d535bd998b52>:198] 2000\n",
      "I0724 16:39:45.710446 140218034444032 <ipython-input-176-d535bd998b52>:198] 3000\n",
      "I0724 16:41:07.350212 140218034444032 <ipython-input-176-d535bd998b52>:198] 4000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Functions and classes for model specifications.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "################### Simple DNase peak based distance model ############\n",
    "\n",
    "class CurriculumModel():\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 test_celltypes,\n",
    "                 matrix,\n",
    "                 assaymap,\n",
    "                 cellmap,  \n",
    "                 debug = False,\n",
    "                 batch_size=64,\n",
    "                 shuffle_size=10,\n",
    "                 prefetch_size=10,\n",
    "                 l1=0.,\n",
    "                 l2=0.,\n",
    "                 lr=1e-3,\n",
    "                 radii=[1,3,10,30], \n",
    "                 train_indices = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        Peak Model\n",
    "        :param data: either a path to TF records OR a dictionary of TRAIN, VALID, and TEST data\n",
    "        :param test_celltypes\n",
    "        :param matrix\n",
    "        :param assaymap\n",
    "        :param cellmap\n",
    "        :param debug: used to print out intermediate validation values\n",
    "        :param batch_size\n",
    "        :param shuffle_size\n",
    "        :param prefetch_size\n",
    "        :param l1\n",
    "        :param l2\n",
    "        :param lr\n",
    "        :param radii\n",
    "        :param train_indices: option numpy array of indices to train from data[Dataset.TRAIN]\n",
    "        \"\"\"\n",
    "        \n",
    "        tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "        assert (set(test_celltypes) < set(list(cellmap))), \\\n",
    "                \"test_celltypes %s must be subsets of available cell types %s\" % (str(test_celltypes), str(list(cellmap)))\n",
    "\n",
    "        # get evaluation cell types by removing any cell types that would be used in test\n",
    "        self.eval_cell_types = list(cellmap).copy()\n",
    "        self.test_celltypes = test_celltypes\n",
    "        [self.eval_cell_types.remove(test_cell) for test_cell in self.test_celltypes]\n",
    "        print(\"eval cell types\", self.eval_cell_types)\n",
    "        self.output_shape, self.train_iter = generator_to_tf_dataset(load_data(data[Dataset.TRAIN],  \n",
    "                                                self.eval_cell_types,\n",
    "                                                self.eval_cell_types,\n",
    "                                                matrix,\n",
    "                                                assaymap,\n",
    "                                                cellmap,\n",
    "                                                radii = radii, mode = Dataset.TRAIN),\n",
    "                                                batch_size, shuffle_size, prefetch_size)\n",
    "\n",
    "        _,            self.valid_iter = generator_to_tf_dataset(load_data(data[Dataset.VALID], \n",
    "                                                self.eval_cell_types,\n",
    "                                                self.eval_cell_types,\n",
    "                                                matrix,\n",
    "                                                assaymap,\n",
    "                                                cellmap,\n",
    "                                                radii = radii, mode = Dataset.VALID), \n",
    "                                                batch_size, 1, prefetch_size)\n",
    "\n",
    "        # can be empty if len(test_celltypes) == 0\n",
    "        _,            self.test_iter = generator_to_tf_dataset(load_data(data[Dataset.TEST], \n",
    "                                               self.test_celltypes, \n",
    "                                               self.eval_cell_types,\n",
    "                                               matrix,\n",
    "                                               assaymap,\n",
    "                                               cellmap,\n",
    "                                               radii = radii, mode = Dataset.TEST),\n",
    "                                               batch_size, 1, prefetch_size)\n",
    "\n",
    "        self.num_outputs = self.output_shape[0]\n",
    "        self.l1, self.l2 = l1, l2\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.prefetch_size = prefetch_size\n",
    "        self.shuffle_size = shuffle_size\n",
    "        self.optimizer = tf.keras.optimizers.Adam(lr=self.lr)\n",
    "\n",
    "        # set self\n",
    "        self.model = self.create_model()\n",
    "        self.radii = radii\n",
    "        self.debug = debug\n",
    "        self.assaymap = assaymap\n",
    "        self.test_celltypes = test_celltypes\n",
    "        self.matrix = matrix\n",
    "        self.assaymap= assaymap \n",
    "        self.cellmap = cellmap\n",
    "        self.data = data\n",
    "\n",
    "            \n",
    "    def save(self, checkpoint_path):\n",
    "        \"\"\"\n",
    "        Saves model.\n",
    "        \n",
    "        :param checkpoint_path: string file path to save model to. \n",
    "        \"\"\"\n",
    "        # save keras model\n",
    "        self.model.save(checkpoint_path)\n",
    "        \n",
    "        # save model params to pickle file\n",
    "        dict_ = {'test_celltypes':self.test_celltypes,\n",
    "                         'matrix':self.matrix,\n",
    "                         'assaymap':self.assaymap,\n",
    "                         'cellmap':self.cellmap,  \n",
    "                         'debug': self.debug,\n",
    "                         'batch_size':self.batch_size,\n",
    "                         'shuffle_size':self.shuffle_size,\n",
    "                         'prefetch_size':self.prefetch_size,\n",
    "                         'radii':self.radii}\n",
    "        \n",
    "        fileObject = open(os.path.join(checkpoint_path, \"model_params.pickle\"),'wb')\n",
    "        pickle.dump(dict_,fileObject)   \n",
    "        fileObject.close()\n",
    "        \n",
    "        \n",
    "    def gini(self, actual, pred, sample_weight):                                                 \n",
    "        df = sorted(zip(actual, pred), key=lambda x : (x[1], x[0]),  reverse=True)\n",
    "        random = [float(i+1)/float(len(df)) for i in range(len(df))]                \n",
    "        totalPos = np.sum([x[0] for x in df])           \n",
    "        cumPosFound = np.cumsum([x[0] for x in df])                                     \n",
    "        Lorentz = [float(x)/totalPos for x in cumPosFound]                          \n",
    "        Gini = np.array([l - r for l, r in zip(Lorentz, random)])\n",
    "        # mask Gini with weights\n",
    "        Gini[np.where(sample_weight == 0)[0]] = 0\n",
    "        return np.sum(Gini)    \n",
    "\n",
    "    def gini_normalized(self, actual, pred, sample_weight = None):              \n",
    "        normalized_gini = self.gini(actual, pred, sample_weight)/self.gini(actual, actual, sample_weight)      \n",
    "        return normalized_gini       \n",
    "\n",
    "    def body_fn(self):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def g(self, p, a=1, B=0, y=1):\n",
    "        \"\"\" Normalization Function. Normalizes loss w.r.t. label proportion.\n",
    "\n",
    "        Constraints: \n",
    "         1. g(p) = 1 when p = 1\n",
    "         2. g(p) = a * p^y + B, where a, y and B are hyperparameters\n",
    "        \"\"\"\n",
    "        return a * tf.math.pow(p, y) + B\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred, weights):\n",
    "        # weighted sum of cross entropy for non 0 weights\n",
    "        # Reduction method = Reduction.SUM_BY_NONZERO_WEIGHTS\n",
    "        # TODO should be neg log likelihood + lk divergence ()\n",
    "        loss = tf.compat.v1.losses.sigmoid_cross_entropy(y_true,  \n",
    "                                                        y_pred, \n",
    "                                                        weights = weights,\n",
    "                                                        reduction = tf.compat.v1.losses.Reduction.SUM_BY_NONZERO_WEIGHTS)\n",
    "\n",
    "        assert(weights.shape)\n",
    "        C = (len(self.assaymap)-1)\n",
    "        p = tf.math.reduce_sum(weights, axis=1)/C # should be of dimension 1 by batch size\n",
    "        normalized_loss = self.g(p)/C * loss\n",
    "        kl = sum(self.model.losses) / weights.shape[-1]\n",
    "        return normalized_loss + kl\n",
    "        \n",
    "    def train(self, num_steps, lr=None, checkpoint_path = None):\n",
    "        if lr == None:\n",
    "            lr = self.lr\n",
    "            \n",
    "        tf.compat.v1.logging.info(\"Starting Training\")\n",
    "\n",
    "#         @tf.function\n",
    "        def train_step(inputs, labels, weights):\n",
    "            logits = self.model(inputs, training=True)\n",
    "            # separate distribution for each TF\n",
    "            # TODO I don't think this distribution is right...\n",
    "            # need to make different cat dist for each column\n",
    "            labels_distribution = tfp.distributions.Binomial(total_count=self.batch_size, logits=logits)\n",
    "            log_likelihood = labels_distribution.log_prob(labels)\n",
    "            \n",
    "            elbo_loss = self.loss_fn(log_likelihood, logits, weights)\n",
    "            print(elbo_loss)\n",
    "            \n",
    "            train_op = self.optimizer.minimize(elbo_loss, self.model.weights)\n",
    "\n",
    "            return elbo_loss\n",
    "        \n",
    "        for step, (inputs, labels, weights) in enumerate(self.train_iter.take(num_steps)): \n",
    "            \n",
    "            self.model.fit(inputs, labels, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "#             loss = train_step(inputs, labels, weights)\n",
    "\n",
    "            if step % 1000 == 0:\n",
    "                tf.compat.v1.logging.info(str(step))\n",
    "                \n",
    "#                 if (self.debug):\n",
    "#                     tf.compat.v1.logging.info(\"On validation\")\n",
    "#                     _, _, _, _, _ = self.test(40000, log=False)\n",
    "#                     tf.compat.v1.logging.info(\"\")\n",
    "\n",
    "    def test(self, num_samples, mode = Dataset.VALID, calculate_metrics=True):\n",
    "        \"\"\"\n",
    "        Tests model on valid and test dataset handlers.\n",
    "        \"\"\"\n",
    "\n",
    "        if (mode == Dataset.VALID):\n",
    "            handle = self.valid_iter # for standard validation of validation cell types\n",
    "            \n",
    "        elif (mode == Dataset.TEST and len(self.test_celltypes) > 0):\n",
    "            handle = self.test_iter # for standard validation of validation cell types        \n",
    "        else:\n",
    "            raise Exception(\"No data exists for %s. Use function test_from_generator() if you want to create a new iterator.\" % (mode))\n",
    "            \n",
    "        return self.run_predictions(num_samples, handle, calculate_metrics)      \n",
    "        \n",
    "    def test_from_generator(self, num_samples, ds, calculate_metrics=True):\n",
    "        \"\"\"\n",
    "        Runs test given a specified data generator \n",
    "        :param num_samples: number of samples to test\n",
    "        :param ds: tensorflow dataset, created by dataset_to_tf_dataset\n",
    "        :param cell_type: cell type to test on. Used to generate holdout indices.\n",
    "        \n",
    "        :return predictions\n",
    "        \"\"\"\n",
    "        return self.run_predictions(num_samples, ds, calculate_metrics)\n",
    "    \n",
    "    def eval_vector(self, data, vector, indices):\n",
    "        \"\"\"\n",
    "        Evaluates a new cell type based on its chromatin (DNase or ATAC-seq) vector. len(vector) should equal\n",
    "        the data.shape[1]\n",
    "        :param data: data to build features from \n",
    "        :param vector: vector of 0s/1s of binding sites TODO AM 4/3/2019: try peak strength instead of 0s/1s\n",
    "        :param indices: indices of vector to actually score. You need all of the locations for the generator.\n",
    "\n",
    "        :return predictions for all factors\n",
    "        \"\"\"\n",
    "        \n",
    "        _,  ds = generator_to_tf_dataset(load_data(data, \n",
    "                 self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 self.matrix,\n",
    "                 self.assaymap,\n",
    "                 self.cellmap,\n",
    "                 radii = self.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 dnase_vector = vector, indices = indices), self.batch_size, 1, self.prefetch_size)\n",
    "\n",
    "        num_samples = len(indices)\n",
    "        \n",
    "        preds, _, _, _, _ = self.run_predictions(num_samples, ds, calculate_metrics = False)    \n",
    "        \n",
    "        return preds\n",
    "\n",
    "    def run_predictions(self, num_samples, iter_, calculate_metrics = True):\n",
    "        \"\"\"\n",
    "        Runs predictions on num_samples records\n",
    "        :param num_samples: number of samples to test\n",
    "        :param iter_: output of self.sess.run(generator_to_one_shot_iterator()), handle to one shot iterator of records\n",
    "        :param log: if true, logs individual factor accuracies\n",
    "        \n",
    "        :return preds, truth, assay_dict, auROC, auPRC, False\n",
    "            preds = predictions, \n",
    "            truth = actual values, \n",
    "            sample_weight: 0/1 weights on predictions.  \n",
    "            assay_dict = if log=True, holds predictions for individual factors\n",
    "            auROC = average macro area under ROC for all factors with truth values\n",
    "            auPRC = average area under PRC for all factors with truth values\n",
    "        \"\"\"\n",
    "        \n",
    "        inv_assaymap = {v: k for k, v in self.assaymap.items()}\n",
    "                \n",
    "        # batches of predictions\n",
    "        vals = []\n",
    "\n",
    "        # TODO: calculate epistemic uncertainty by iterating over a certain number of times,\n",
    "        # getting y_preds. You can then calculate the mean and sigma of the predictions, \n",
    "        # and use this to gather uncertainty: (see http://krasserm.github.io/2019/03/14/bayesian-neural-networks/)\n",
    "        for inputs, labels, weights in iter_.take(int(num_samples / self.batch_size)+1): \n",
    "            vals.append([tf.sigmoid(self.model(inputs, training=False)), inputs, labels, weights])\n",
    "\n",
    "        preds = np.concatenate([v[0] for v in vals])\n",
    "        preds = preds[:num_samples] # get feature row\n",
    "\n",
    "        truth = np.concatenate([v[2] for v in vals])[:num_samples]\n",
    "        sample_weight  = np.concatenate([v[3] for v in vals])[:num_samples]\n",
    "        \n",
    "        # reset truth back to 0 to compute metrics\n",
    "        # sample weights will rule these out anyways when computing metrics\n",
    "        truth_reset = np.copy(truth)\n",
    "        truth_reset[truth_reset < Label.UNBOUND.value] = 0 \n",
    "                                           \n",
    "        # do not continue to calculate metrics. Just return predictions and true values\n",
    "        if (not calculate_metrics):\n",
    "            return preds, truth, sample_weight, None, None, None\n",
    "\n",
    "        assert(preds.shape == sample_weight.shape)\n",
    "\n",
    "        try:\n",
    "            # Mean results because sample_weight mask can only work on 1 row at a time.\n",
    "            # If a given assay is not available for evaluation, sample_weights will all be 0 \n",
    "            # and the resulting roc_auc_score will be NaN.\n",
    "            auROC_vec = []\n",
    "            auPRC_vec = []\n",
    "            GINI_vec =  []\n",
    "\n",
    "\n",
    "            # try/accept for cases with only one class (throws ValueError)\n",
    "            assay_dict = {}\n",
    "\n",
    "            for j in range(preds.shape[1]): # for all assays\n",
    "                assay = inv_assaymap[j+1] \n",
    "\n",
    "                roc_score = np.NAN\n",
    "\n",
    "                try:\n",
    "                    roc_score = sklearn.metrics.roc_auc_score(truth_reset[:,j], preds[:,j], \n",
    "                                                      average='macro', \n",
    "                                                      sample_weight = sample_weight[:,j])\n",
    "\n",
    "                    auROC_vec.append(roc_score)\n",
    "\n",
    "                except ValueError:\n",
    "                    roc_score = np.NaN\n",
    "\n",
    "                try:\n",
    "                    pr_score = sklearn.metrics.average_precision_score(truth_reset[:,j], preds[:,j], \n",
    "                                                             sample_weight = sample_weight[:, j])\n",
    "\n",
    "                    auPRC_vec.append(pr_score)\n",
    "\n",
    "                except ValueError:\n",
    "                    pr_score = np.NaN\n",
    "\n",
    "                try:\n",
    "                    gini_score = self.gini_normalized(truth_reset[:,j], preds[:,j], \n",
    "                                                      sample_weight = sample_weight[:, j])\n",
    "\n",
    "                    GINI_vec.append(gini_score)\n",
    "\n",
    "                except ValueError:\n",
    "                    gini_score = np.NaN\n",
    "\n",
    "                assay_dict[assay] = {\"AUC\": roc_score, \"auPRC\": pr_score, \"GINI\": gini_score }\n",
    "\n",
    "\n",
    "            auROC = np.nanmean(auROC_vec)\n",
    "            auPRC = np.nanmean(auPRC_vec)\n",
    "\n",
    "            tf.compat.v1.logging.info(\"macro auROC:     \" + str(auROC))\n",
    "            tf.compat.v1.logging.info(\"auPRC:     \" + str(auPRC))\n",
    "            tf.compat.v1.logging.info(\"GINI:     \" + str(np.nanmean(GINI_vec)))\n",
    "        except ValueError as v:\n",
    "            auROC = None\n",
    "            auPRC = None\n",
    "            tf.compat.v1.logging.info(\"Failed to calculate metrics\")\n",
    "\n",
    "        return preds, truth, sample_weight, assay_dict, auROC, auPRC\n",
    "        \n",
    "    def score_peak_file(self, peak_file):\n",
    "    \n",
    "        # get peak_vector, which is a vector matching train set. Some peaks will not overlap train set, \n",
    "        # and their indices are stored in missing_idx for future use\n",
    "        peak_vector, all_peaks = bedFile2Vector(peak_file)\n",
    "        print(\"finished loading peak file\")\n",
    "\n",
    "        # only select peaks to score\n",
    "        idx = np.where(peak_vector == 1)[0]\n",
    "        \n",
    "        if len(idx) == 0:\n",
    "            raise ValueError(\"No positive peaks found in %s\" % peak_file)\n",
    "\n",
    "        all_data = np.concatenate((self.data[Dataset.TRAIN], self.data[Dataset.VALID], self.data[Dataset.TEST]), axis=1)\n",
    "\n",
    "        # takes about 1.5 minutes for 100,000 regions TODO AM 4/3/2019 speed up generator\n",
    "        predictions = self.eval_vector(all_data, peak_vector, idx)\n",
    "        print(\"finished predictions...\", predictions.shape)\n",
    "\n",
    "\n",
    "        # get number of factors to fill in if values are missing\n",
    "        num_factors = predictions[0].shape[0]\n",
    "\n",
    "        # map predictions with genomic position \n",
    "        liRegions = load_allpos_regions()\n",
    "        prediction_positions = itemgetter(*idx)(liRegions)\n",
    "        zipped = list(zip(prediction_positions, predictions))\n",
    "\n",
    "        # for each all_peaks, if 1, reduce means for all overlapping peaks in positions\n",
    "        # else, set to 0s\n",
    "\n",
    "        def reduceMeans(peak):\n",
    "            if (peak[1] == 1):\n",
    "                # parse region\n",
    "\n",
    "                # filter overlapping predictions for this peak and take mean      \n",
    "                res = map(lambda k: k[1], filter(lambda x: peak[0].overlaps(x[0], 100), zipped))\n",
    "                arr = np.concatenate(list(map(lambda x: np.matrix(x), res)), axis = 0)\n",
    "                return(peak[0], np.mean(arr, axis = 0))\n",
    "            else:\n",
    "                return(peak[0], np.zeros(num_factors)) \n",
    "\n",
    "        grouped = list(map(lambda x: np.matrix(reduceMeans(x)[1]), all_peaks))\n",
    "\n",
    "        final = np.concatenate(grouped, axis=0)\n",
    "\n",
    "        df = pd.DataFrame(final, columns=list(self.assaymap)[1:])\n",
    "\n",
    "        # load in peaks to get positions and could be called only once\n",
    "        # TODO why are you reading this in twice?\n",
    "        df_pos = pd.read_csv(peak_file, sep=\"\\t\", header = None)[[0,1,2]]\n",
    "        final_df = pd.concat([df_pos, df], axis=1)\n",
    "\n",
    "        return final_df\n",
    "            \n",
    "\n",
    "class CLP(CurriculumModel):\n",
    "    def __init__(self,\n",
    "             *args,\n",
    "             **kwargs):\n",
    "\n",
    "        \"\"\" To resume model training, call:\n",
    "            model2 = MLP(data = data, checkpoint=\"/home/eecs/akmorrow/epitome/out/models/test_model\")\n",
    "        \"\"\"\n",
    "        self.layers = 4\n",
    "        self.num_units = [100, 100, 100, 50]\n",
    "        self.activation = tf.tanh\n",
    "                          \n",
    "        if \"checkpoint\" in kwargs.keys():\n",
    "            fileObject = open(kwargs[\"checkpoint\"] + \"/model_params.pickle\" ,'rb')\n",
    "            metadata = pickle.load(fileObject)\n",
    "            CurriculumModel.__init__(self, kwargs[\"data\"], **metadata)\n",
    "            self.model = tf.keras.models.load_model(kwargs[\"checkpoint\"])\n",
    "            \n",
    "        elif \"model\" in kwargs.keys():\n",
    "            # load in programmatic model with weights\n",
    "            CurriculumModel.__init__(self, *args)\n",
    "            self.model = kwargs[\"model\"]\n",
    "        else: \n",
    "            CurriculumModel.__init__(self, *args)\n",
    "            \n",
    "            \n",
    "    # TODO:how do you incorporate weights into this?\n",
    "    def neg_log_likelihood(self, y_obs, y_pred, sigma=1):\n",
    "        from tensorflow.keras import backend as K\n",
    "        dist = tfp.distributions.Normal(loc=y_pred, scale=sigma)\n",
    "        return K.sum(-dist.log_prob(y_obs))\n",
    "\n",
    "    def create_model(self):\n",
    "        \n",
    "        # this is called like model(data, training = True)\n",
    "        model = tf.keras.Sequential()\n",
    "        \n",
    "        if not isinstance(self.num_units, collections.Iterable):\n",
    "            self.num_units = [self.num_units] * self.layers\n",
    "        for i in range(self.layers):\n",
    "            model.add(tfp.layers.DenseVariational(self.num_units[i], posterior_mean_field, prior_trainable, activation = self.activation))\n",
    "\n",
    "        # output layer\n",
    "        model.add(tfp.layers.DenseVariational(self.num_outputs, posterior_mean_field,prior_trainable))\n",
    "        from tensorflow.keras import callbacks, optimizers\n",
    "        model.compile(loss=self.neg_log_likelihood, optimizer=optimizers.Adam(lr=0.03))\n",
    "        \n",
    "        return model\n",
    "\n",
    "clp_model = CLP(data,\n",
    "        [],\n",
    "        matrix,\n",
    "        assaymap,\n",
    "        cellmap,\n",
    "        shuffle_size=2, \n",
    "        batch_size=64)\n",
    "\n",
    "clp_model.train(5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clp_model.test(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the surrogate posterior over `keras.layers.Dense` `kernel` and `bias`.\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  c = np.log(np.expm1(1.))\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(2 * n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfp.distributions.Independent(\n",
    "          tfp.distributions.Normal(loc=t[..., :n],\n",
    "                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])\n",
    "# Specify the prior over `keras.layers.Dense` `kernel` and `bias`.\n",
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "  n = kernel_size + bias_size\n",
    "  return tf.keras.Sequential([\n",
    "      tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "      tfp.layers.DistributionLambda(lambda t: tfp.distributions.Independent(\n",
    "          tfp.distributions.Normal(loc=t, scale=1),\n",
    "          reinterpreted_batch_ndims=1)),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: 3 TFs for batch size 16\n",
    "batch = 4\n",
    "TF = 2\n",
    "labels = np.random.randint(2, size=[batch, TF])\n",
    "logits = np.random.rand(batch, TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([[1, 1],\n",
    "                   [1, 0],\n",
    "                   [1, 0],\n",
    "                   [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = np.array([[0.2, 0.79676108],\n",
    "                   [0.97566671, 0.97438886],\n",
    "                   [0.06605159, 0.37975895],\n",
    "                   [0.27634663, 0.63438325]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'total_count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-746b968c0d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'total_count'"
     ]
    }
   ],
   "source": [
    "tfp.distributions.Binomial(logits=logits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeEnv_c76",
   "language": "python",
   "name": "epitomeenv_c76"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing single vs multilabel models\n",
    "Alyssa's 11/6\n",
    "\n",
    "Question: Does single vs multiple labels perform better?\n",
    "\n",
    "In this file, we first test the SMC3/Rad21/CTCF complex.\n",
    "\n",
    "We then run all single model TFs on 20,000 iterations.\n",
    "\n",
    "\n",
    "Answer is that it really depends on the TFs being chosen. Some perform better alone, some perform better with others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "\n",
    "import pyDNase\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import kipoi\n",
    "import os\n",
    "import pybedtools\n",
    "import torch\n",
    "import h5sparse\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from pyDNase import GenomicInterval\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "\n",
    "from scipy.fftpack import fft, ifft\n",
    "\n",
    "import sys\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paths for this user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to where dnase bams are stored. Bams need to be sorted and indexed. See bin/download_dnase_encode.sh for\n",
    "# data processing\n",
    "# Required in constants.py\n",
    "# _ENCODE_DATA_PREFIX =  \"/data/akmorrow/encode_data/\"\n",
    "\n",
    "# # where training data is stored\n",
    "# deepsea_path = \"/data/akmorrow/epitome_data/deepsea_train/\"\n",
    "\n",
    "feature_path = '../data/feature_name'\n",
    "\n",
    "output_path = '/home/eecs/akmorrow/epitome/out/Epitome'\n",
    "\n",
    "data_path = \"/data/akmorrow/epitome_data/deepsea_labels_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exec(open(\"../constants.py\").read())\n",
    "exec(open(\"../functions.py\").read())\n",
    "exec(open(\"../generators.py\").read())\n",
    "exec(open(\"../models.py\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load DeepSEA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = load_deepsea_label_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919, 408000) (919, 4455024) (919, 455024)\n"
     ]
    }
   ],
   "source": [
    "print(valid_data[\"y\"].shape, train_data[\"y\"].shape, test_data[\"y\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose cell types and assays\n",
    "\n",
    "Here, we choose SMC3, CTCF, and Rad21, a well known complex that is correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on  all 3 TFs\n",
    "\n",
    "['DNase', 'Rad21', 'CTCF', 'SMC3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Available cell types\n",
    "validation_celltypes = [\"K562\"] # we remove hepg2 from the validation, as there are so few SMC3 cell types to begin with \n",
    "test_celltypes = [\"HepG2\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well did we perform on A549 using all 3 TFs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6db3e68748>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path='../../data/feature_name', \n",
    "                                  eligible_assays = None,\n",
    "                                  eligible_cells = None, min_cells_per_assay = 2, min_assays_per_cell=5)\n",
    "    \n",
    "inv_assaymap = {v: k for k, v in assaymap.items()}\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(np.arange(len(assaymap)), rotation = 90)\n",
    "ax.set_xticklabels(assaymap.keys())\n",
    "plt.yticks(np.arange(len(cellmap)))\n",
    "ax.set_yticklabels(cellmap.keys())\n",
    "plt.imshow(matrix!=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval cell types ['SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549']\n",
      "using ['SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "using ['HepG2'] as labels for mode Dataset.TEST\n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/EpitomeEnv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing variables\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:1000 0.606929\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.959133762756\n",
      "INFO:tensorflow:Our micro AUC:     0.959133762756\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 0.0278339\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.95978293593\n",
      "INFO:tensorflow:Our micro AUC:     0.95978293593\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 0.00861721\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.96583775779\n",
      "INFO:tensorflow:Our micro AUC:     0.96583775779\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 0.0156686\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.961813978834\n",
      "INFO:tensorflow:Our micro AUC:     0.961813978834\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:5000 0.254632\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.965727189548\n",
      "INFO:tensorflow:Our micro AUC:     0.965727189548\n",
      "INFO:tensorflow:\n"
     ]
    }
   ],
   "source": [
    "radii = [1,3,10,30]\n",
    "model = MLP(4, [100, 100, 100, 50], \n",
    "            tf.tanh, \n",
    "            train_data, \n",
    "            valid_data, \n",
    "            test_data, \n",
    "            test_celltypes,\n",
    "            gen_from_peaks, \n",
    "            matrix,\n",
    "            assaymap,\n",
    "            cellmap,\n",
    "            shuffle_size=2, \n",
    "            radii=radii)\n",
    "model.train(20000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Our macro AUC:     0.958331269719\n",
      "INFO:tensorflow:Our micro AUC:     0.958331269719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/EpitomeEnv/lib/python3.6/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = tps / (tps + fps)\n"
     ]
    }
   ],
   "source": [
    "test_DNase = model.test(455024, log=True)\n",
    "\n",
    "\n",
    "# INFO:tensorflow:2018-12-05 12:19:02.977124: 0, DNase, NaN\n",
    "# INFO:tensorflow:2018-12-05 12:19:02.979063: 1, Rad21, 0.936362\n",
    "# INFO:tensorflow:2018-12-05 12:19:03.135981: 2, CTCF, 0.972709\n",
    "# INFO:tensorflow:2018-12-05 12:19:03.300613: 3, SMC3, 0.905783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00776174,  0.0111055 ,  0.01409647],\n",
       "        [ 0.00702672,  0.00960908,  0.01299283],\n",
       "        [ 0.00754961,  0.01068342,  0.01376804],\n",
       "        ..., \n",
       "        [ 0.01300736,  0.02671668,  0.02711702],\n",
       "        [ 0.0109169 ,  0.01609266,  0.01691344],\n",
       "        [ 0.07065497,  0.11577307,  0.08959483]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]], dtype=float32),\n",
       " {'CTCF': {'AUC': 0.96921207273245069,\n",
       "   'GINI': 0.93842455835965499,\n",
       "   'auPRC': 0.66959315982241596},\n",
       "  'Rad21': {'AUC': 0.94812406335683352,\n",
       "   'GINI': 0.89625013512858376,\n",
       "   'auPRC': 0.60837253216734022},\n",
       "  'SMC3': {'AUC': 0.95765767306660565,\n",
       "   'GINI': 0.70143988061727014,\n",
       "   'auPRC': 0.61844290285714454}},\n",
       " 0.95833126971862992,\n",
       " 0.95833126971862992)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_DNase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running just SMC3, Rad21, and CTCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p300',\n",
       " 'c-Myc',\n",
       " 'c-Jun',\n",
       " 'c-Fos',\n",
       " 'Znf143',\n",
       " 'ZZZ3',\n",
       " 'ZNF274',\n",
       " 'ZBTB7A',\n",
       " 'ZBTB33',\n",
       " 'YY1',\n",
       " 'USF2',\n",
       " 'USF-1',\n",
       " 'TR4',\n",
       " 'TFIIIC-110',\n",
       " 'TEAD4',\n",
       " 'TCF7L2',\n",
       " 'TCF12',\n",
       " 'TBP',\n",
       " 'TBLR1',\n",
       " 'TAF7',\n",
       " 'TAF1',\n",
       " 'Sin3Ak-20',\n",
       " 'STAT5A',\n",
       " 'STAT3',\n",
       " 'STAT1',\n",
       " 'SRF',\n",
       " 'SP2',\n",
       " 'SP1',\n",
       " 'SMC3',\n",
       " 'SIX5',\n",
       " 'SIN3A',\n",
       " 'Rad21',\n",
       " 'RXRA',\n",
       " 'RPC155',\n",
       " 'RFX5',\n",
       " 'RBBP5',\n",
       " 'Pol3',\n",
       " 'Pol2-4H8',\n",
       " 'Pol2(phosphoS2)',\n",
       " 'Pol2(b)',\n",
       " 'Pol2',\n",
       " 'PU.1',\n",
       " 'POU2F2',\n",
       " 'PML',\n",
       " 'PAX5-C20',\n",
       " 'Nrf1',\n",
       " 'NRSF',\n",
       " 'NFKB',\n",
       " 'NFIC',\n",
       " 'NF-YB',\n",
       " 'NF-YA',\n",
       " 'NF-E2',\n",
       " 'Mxi1',\n",
       " 'Max',\n",
       " 'MafK',\n",
       " 'MafF',\n",
       " 'MEF2A',\n",
       " 'MAZ',\n",
       " 'JunD',\n",
       " 'Ini1',\n",
       " 'IRF3',\n",
       " 'HDAC2',\n",
       " 'HA-E2F1',\n",
       " 'GTF2F1',\n",
       " 'GATA3',\n",
       " 'GATA-2',\n",
       " 'GABP',\n",
       " 'FOXA1',\n",
       " 'FOSL2',\n",
       " 'FOSL1',\n",
       " 'Egr-1',\n",
       " 'EZH2',\n",
       " 'ETS1',\n",
       " 'ELK1',\n",
       " 'ELF1',\n",
       " 'E2F6',\n",
       " 'E2F4',\n",
       " 'CTCF',\n",
       " 'COREST',\n",
       " 'CHD2',\n",
       " 'CHD1',\n",
       " 'CEBPB',\n",
       " 'Brg1',\n",
       " 'Bach1',\n",
       " 'BRF2',\n",
       " 'BRF1',\n",
       " 'BRCA1',\n",
       " 'BHLHE40',\n",
       " 'BDP1',\n",
       " 'BCLAF1',\n",
       " 'BCL3',\n",
       " 'BCL11A',\n",
       " 'ATF3',\n",
       " 'ATF2',\n",
       " 'ARID3A']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = list(assaymap)[1:]\n",
    "eligible_cells = list(cellmap)\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_assays_from_feature_file(feature_path, \n",
    "                                 eligible_assays = None, \n",
    "                                 eligible_cells = None,\n",
    "                                 min_cells_per_assay= 3, \n",
    "                                 min_assays_per_cell = 2):\n",
    "    ''' Parses a feature name file from DeepSea. File can be found in repo at ../data/feature_name.\n",
    "    Returns at matrix of cell type/assays which exist for a subset of cell types.\n",
    "    NOTE: this changes the ordering from the previous function. Dnase is not first.\n",
    "\n",
    "    Args:\n",
    "        :param feature_path: location of feature_path\n",
    "        :param eligible_assays: list of assays to filter by (ie [\"CTCF\", \"EZH2\", ..]). If None, then returns all assays.\n",
    "        Note that DNase will always be included in the factors, as it is required by the method.\n",
    "        :param eligible_cells: list of cells to filter by (ie [\"HepG2\", \"GM12878\", ..]). If None, then returns all cell types.\n",
    "        :param min_cells_per_assay: number of cell types an assay must have to be considered\n",
    "        :param min_assays_per_cell: number of assays a cell type must have to be considered. Includes DNase.\n",
    "    Returns\n",
    "        matrix: cell type by assay matrix\n",
    "        cellmap: index of cells\n",
    "        assaymap: index of assays\n",
    "    '''\n",
    "\n",
    "    # check argument validity\n",
    "    if (min_assays_per_cell < 2):     \n",
    "         print(\"Warning: min_assays_per_cell should not be < 2 (this means it only has DNase) but was set to %i\" % min_assays_per_cell)\n",
    "         \n",
    "    \n",
    "    if (min_cells_per_assay < 2):     \n",
    "         print(\"Warning: min_cells_per_assay should not be < 2 (this means you may only see it in test) but was set to %i\" % min_cells_per_assay)\n",
    "         \n",
    "    if (eligible_assays != None):     \n",
    "        if (len(eligible_assays) + 1 < min_assays_per_cell):\n",
    "            raise Exception(\"\"\"%s is less than the minimum assays required (%i). \n",
    "            Lower min_assays_per_cell to (%i) if you plan to use only %i eligible assays\"\"\" \\\n",
    "                            % (eligible_assays, min_assays_per_cell, len(eligible_assays)+1, len(eligible_assays)))\n",
    "\n",
    "    if (eligible_cells != None):     \n",
    "        if (len(eligible_cells) + 1 < min_cells_per_assay):\n",
    "            raise Exception(\"\"\"%s is less than the minimum cells required (%i). \n",
    "            Lower min_cells_per_assay to (%i) if you plan to use only %i eligible cells\"\"\" \\\n",
    "                            % (eligible_cells, min_cells_per_assay, len(eligible_cells)+1, len(eligible_cells)))\n",
    "            \n",
    "    # TFs are 126 to 816 and DNase is 1 to 126, TFs are 126 to 816\n",
    "    # We don't want to include histone information.\n",
    "    elegible_assay_indices  = np.linspace(1,815, num=815).astype(int)\n",
    "\n",
    "    # TODO want a dictionary of assay: {list of cells}\n",
    "    # then filter out assays with less than min_cells_per_assay cells\n",
    "    # after this, there may be some unused cells so remove those as well\n",
    "    with open(feature_path) as f:\n",
    "\n",
    "        indexed_assays={}    # dict of {cell: {dict of indexed assays} }\n",
    "        for i,l in enumerate(f):\n",
    "            if i not in elegible_assay_indices: \n",
    "                continue # skip first rows and non-transcription factors\n",
    "\n",
    "            # for example, split '8988T|DNase|None' \n",
    "            cell, assay = l.split('\\t')[1].split('|')[:2]\n",
    "\n",
    "            # check if cell and assay is valid\n",
    "            valid_cell = (eligible_cells == None) or (cell in eligible_cells) \n",
    "            valid_assay = (eligible_assays == None) or (assay in eligible_assays) or (assay == \"DNase\")\n",
    "\n",
    "            # if cell and assay is valid, add it in\n",
    "            if valid_cell and valid_assay:\n",
    "                if cell not in indexed_assays:\n",
    "                    indexed_assays[cell] = {assay: i-1} # add index of assay\n",
    "                else:\n",
    "                    indexed_assays[cell][assay] = i-1\n",
    "\n",
    "\n",
    "\n",
    "    # finally filter out cell types with < min_assays_per_cell and have DNase\n",
    "    indexed_assays = {k: v for k, v in indexed_assays.items() if 'DNase' in v.keys() and len(v) >= min_assays_per_cell}\n",
    "\n",
    "    # make flatten list of assays from cells\n",
    "    tmp = [list(v) for k, v in indexed_assays.items()]\n",
    "    tmp = [item for sublist in tmp for item in sublist]\n",
    "\n",
    "    # list of assays that meet min_cell criteria\n",
    "    valid_assays = {k:v for k, v in Counter(tmp).items() if v >= min_cells_per_assay}\n",
    "    \n",
    "    # remove invalid assays from indexed_assays\n",
    "    for key, values in indexed_assays.items():\n",
    "        \n",
    "        # remove assays that do not mean min_cell criteria\n",
    "        new_v = {k: v for k, v in values.items() if k in valid_assays.keys()}\n",
    "        indexed_assays[key] = new_v \n",
    "    \n",
    "    potential_assays = valid_assays.keys()\n",
    "    cells = indexed_assays.keys()\n",
    "\n",
    "    # sort cells alphabetical\n",
    "    cells = sorted(cells, reverse=True)\n",
    "    \n",
    "    # sort assays alphabetically\n",
    "    potential_assays = sorted(potential_assays, reverse=True)\n",
    "    \n",
    "    # make sure DNase is first assay. This is because the model\n",
    "    # assumes the first column specifies DNase \n",
    "    potential_assays.remove(\"DNase\")\n",
    "    potential_assays.insert(0,\"DNase\")\n",
    "\n",
    "    cellmap = {cell: i for i, cell in enumerate(cells)}\n",
    "    assaymap = {assay: i for i, assay in enumerate(potential_assays)}\n",
    "\n",
    "    matrix = np.zeros((len(cellmap), len(assaymap))) - 1\n",
    "    for cell in cells:\n",
    "        for assay, _ in indexed_assays[cell].items():\n",
    "            matrix[cellmap[cell], assaymap[assay]] = indexed_assays[cell][assay]\n",
    "\n",
    "    matrix = matrix.astype(int) \n",
    "    return matrix, cellmap, assaymap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running on assay p300...\n",
      "{'T-47D': 0, 'SK-N-SH_RA': 1, 'K562': 2, 'HepG2': 3, 'HeLa-S3': 4, 'H1-hESC': 5, 'GM12878': 6, 'A549': 7}\n",
      "['HepG2']\n",
      "eval cell types ['T-47D', 'SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549']\n",
      "using ['T-47D', 'SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['T-47D', 'SK-N-SH_RA', 'K562', 'HeLa-S3', 'H1-hESC', 'GM12878', 'A549'] as labels for mode Dataset.VALID\n",
      "using ['HepG2'] as labels for mode Dataset.TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/EpitomeEnv/lib/python3.6/site-packages/tensorflow/python/client/session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/akmorrow/anaconda2/envs/EpitomeEnv/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing variables\n",
      "INFO:tensorflow:Starting Training\n",
      "INFO:tensorflow:1000 0.419568\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.851044764635\n",
      "INFO:tensorflow:Our micro AUC:     0.851044764635\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:2000 0.0270678\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.845228054516\n",
      "INFO:tensorflow:Our micro AUC:     0.845228054516\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:3000 0.0591824\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.850524763949\n",
      "INFO:tensorflow:Our micro AUC:     0.850524763949\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:4000 0.0548691\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.84987389615\n",
      "INFO:tensorflow:Our micro AUC:     0.84987389615\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:5000 0.0516278\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.812337199814\n",
      "INFO:tensorflow:Our micro AUC:     0.812337199814\n",
      "INFO:tensorflow:\n",
      "INFO:tensorflow:6000 0.434922\n",
      "INFO:tensorflow:On validation\n",
      "INFO:tensorflow:Our macro AUC:     0.837801463321\n",
      "INFO:tensorflow:Our micro AUC:     0.837801463321\n",
      "INFO:tensorflow:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "time = datetime.datetime.now().time().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "\n",
    "file = open('/data/akmorrow/epitome_data/out/tmp_prediction_aucs_singleTFs_%s.json' % time, 'w')\n",
    "\n",
    "for assay in factors:\n",
    "\n",
    "    print(\" Running on assay %s...\" % assay)\n",
    "\n",
    "    label_assays = ['DNase', assay]\n",
    "    \n",
    "    try: \n",
    "        matrix, cellmap, assaymap = get_assays_from_feature_file(feature_path='../../data/feature_name', eligible_assays = [\"DNase\", assay], \n",
    "                                     eligible_cells = eligible_cells)\n",
    "        print(cellmap)\n",
    "        print(test_celltypes)\n",
    "        \n",
    "\n",
    "        file.write('%s\\n' % (assay))\n",
    "        file.flush()\n",
    "\n",
    "        model = MLP(4, [100, 100, 100, 50], \n",
    "                    tf.tanh, \n",
    "                    train_data, \n",
    "                    valid_data, \n",
    "                    test_data, \n",
    "                    test_celltypes,\n",
    "                    gen_from_peaks, \n",
    "                    matrix,\n",
    "                    assaymap,\n",
    "                    cellmap,\n",
    "                    shuffle_size=2, \n",
    "                    radii=radii)\n",
    "        model.train(20000)\n",
    "\n",
    "        test_DNase_1 = model.test(455024, log=True)\n",
    "\n",
    "        file.write(json.dumps(test_DNase_1[2]))\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "        # flush to file\n",
    "        file.flush()\n",
    "    except:\n",
    "        print(\"%s failed\" % assay)\n",
    "        file.write(\"%s failed\" % assay)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "############## END TRIO EXPERIMENTS ##############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

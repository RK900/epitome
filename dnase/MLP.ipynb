{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration Notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics\n",
    "import os\n",
    "import h5sparse\n",
    "import datetime\n",
    "import logging\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from epitome.functions import *\n",
    "from epitome.models import *\n",
    "import datetime\n",
    "import sys\n",
    "import scipy.stats as stats\n",
    "import yaml\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/eecs/akmorrow/epitome/config.yml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data, valid_data, test_data = load_epitome_data(config['epitome_data_dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, valid_data, test_data = load_epitome_data(config['epitome_data_dir'])\n",
    "data = {Dataset.TRAIN: train_data, Dataset.VALID: valid_data, Dataset.TEST: test_data}\n",
    "print(data[Dataset.TRAIN].shape, data[Dataset.VALID].shape, data[Dataset.TEST].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation and Test Cell Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get matrix of cell types and assays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assays = ['DNase', 'ZZZ3', 'ZNF274', 'ZBTB7A', 'ZBTB33', 'YY1', 'USF2', 'TEAD4', 'TCF7L2', 'TCF12', 'TBP', 'TAF1', 'STAT5A', 'STAT3', 'STAT1', 'SRF', 'SP2', 'SP1', 'SMC3', 'SIX5', 'RXRA', 'RFX5', 'POU2F2', 'PML', 'NFIC', 'MEF2A', 'MAZ', 'IRF3', 'HDAC2', 'GTF2F1', 'FOXA1', 'FOSL2', 'EZH2', 'ETS1', 'ELK1', 'ELF1', 'E2F6', 'E2F4', 'CTCF', 'CHD2', 'CHD1', 'CEBPB', 'BRCA1', 'BHLHE40', 'BCLAF1', 'BCL3', 'ATF3', 'ARID3A']\n",
    "\n",
    "cells = ['MCF-7', 'K562', 'HepG2', 'HeLa-S3', 'GM12892', 'GM12891', 'GM12878', 'A549']\n",
    "\n",
    "print(len(cells), len(assays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, cellmap, assaymap = get_assays_from_feature_file(EPITOME_FEATURE_NAME_FILE,\n",
    "                                  eligible_assays = assays,\n",
    "                                  eligible_cells = cells, min_cells_per_assay = 2, min_assays_per_cell=2)\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(np.arange(len(assaymap)), rotation = 90)\n",
    "ax.set_xticklabels(assaymap.keys())\n",
    "plt.yticks(np.arange(len(cellmap)))\n",
    "ax.set_yticklabels(cellmap.keys())\n",
    "\n",
    "plt.imshow(matrix!=-1)\n",
    "print(len(assaymap), len(cellmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, valid_data, test_data = load_epitome_data(config['epitome_data_dir'])\n",
    "dtrain_data, dvalid_data, dtest_data = load_deepsea_label_data(config[\"deepsea_data_path\"])\n",
    "ddata = {Dataset.TRAIN: dtrain_data, Dataset.VALID: dvalid_data, Dataset.TEST: dtest_data}\n",
    "print(ddata[Dataset.TRAIN].shape, ddata[Dataset.VALID].shape, ddata[Dataset.TEST].shape)\n",
    "\n",
    "dmatrix, dcellmap, dassaymap = get_assays_from_feature_file(DEEPSEA_FEATURE_NAME_FILE,\n",
    "                                  eligible_assays = assays,\n",
    "                                  eligible_cells = cells, min_cells_per_assay = 2, min_assays_per_cell=2)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,10))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_aspect('equal')\n",
    "plt.xticks(np.arange(len(dassaymap)), rotation = 90)\n",
    "ax.set_xticklabels(dassaymap.keys())\n",
    "plt.yticks(np.arange(len(dcellmap)))\n",
    "ax.set_yticklabels(dcellmap.keys())\n",
    "\n",
    "plt.imshow(dmatrix!=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "test_celltypes = ['A549'] # most available cell types\n",
    "\n",
    "model = MLP(data,\n",
    "            test_celltypes,\n",
    "            matrix,\n",
    "            assaymap,\n",
    "            cellmap,\n",
    "            shuffle_size=2, \n",
    "            batch_size=64)\n",
    "        \n",
    "model.train(10)\n",
    "model.score_peak_file(\"/home/eecs/akmorrow/epitome/data/test.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitome.models import *\n",
    "test_celltypes = ['A549'] # most available cell types\n",
    "\n",
    "model2 = MLP(ddata,\n",
    "            test_celltypes,\n",
    "            dmatrix,\n",
    "            dassaymap,\n",
    "            dcellmap,\n",
    "            shuffle_size=2, \n",
    "            batch_size=64)\n",
    "        \n",
    "model2.train(3000)\n",
    "model.score_peak_file(\"/home/eecs/akmorrow/epitome/data/test.bed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_celltypes = ['A549'] # most available cell types\n",
    "\n",
    "model = MLP(data,\n",
    "            test_celltypes,\n",
    "            matrix,\n",
    "            assaymap,\n",
    "            cellmap,\n",
    "            shuffle_size=2, \n",
    "            batch_size=64)\n",
    "        \n",
    "model.train(5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.score_peak_file(\"/home/eecs/akmorrow/epitome/data/test.bed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitome.generators import *\n",
    "_, g = generator_to_tf_dataset(load_data(data[Dataset.VALID], \n",
    "                                               model.eval_cell_types, \n",
    "                                               model.eval_cell_types,\n",
    "                                               model.matrix,\n",
    "                                               model.assaymap,\n",
    "                                               model.cellmap,\n",
    "                                               radii = model.radii, mode = Dataset.VALID),\n",
    "                                               model.batch_size, 1, model.prefetch_size)\n",
    "results2_epitome = model2.test_from_generator(4000 * len(model2.eval_cell_types), g)\n",
    "\n",
    "\n",
    "_, g = generator_to_tf_dataset(load_data(data[Dataset.VALID], \n",
    "                                               model.eval_cell_types, \n",
    "                                               model.eval_cell_types,\n",
    "                                               model.matrix,\n",
    "                                               model.assaymap,\n",
    "                                               model.cellmap,\n",
    "                                               radii = model.radii, mode = Dataset.VALID),\n",
    "                                               model.batch_size, 1, model.prefetch_size)\n",
    "results_original_epitome = model.test_from_generator(4000 * len(model.eval_cell_types), g)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from epitome.viz import *\n",
    "for i in results2_epitome [3][\"CTCF\"].keys():\n",
    "    joint_plot(results2_epitome [3], results_original_epitome[3],\n",
    "               metric = i,\n",
    "               model1_name = \"DeepSEA_data\", \n",
    "               model2_name = \"new_dataset\",\n",
    "                outlier_filter = 'new_dataset < DeepSEA_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look for correlation between cell type counts and performace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix2 = np.copy(matrix)\n",
    "# remove test celltypes\n",
    "matrix2 = np.delete(matrix2, cellmap[test_celltypes[0]], 0)\n",
    "matrix3 = np.copy(matrix)\n",
    "matrix3 = np.delete(matrix3, cellmap[test_celltypes[0]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "matrix2[matrix2 >= 0]  = 1\n",
    "matrix2[matrix2 == -1]  = 0\n",
    "tmp = np.sum(matrix2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [(k, v['AUC']) for (k, v) in assay_dict.items()]\n",
    "zipped = zip(tmp, t)\n",
    "\n",
    "k = list(filter(lambda x: not np.isnan(x[1][1]),  zipped))\n",
    "\n",
    "x = list(map(lambda x: x[0], k))\n",
    "y = list(map(lambda x: x[1][1], k))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.set_xlabel('Number of cell types for each factor in train')\n",
    "ax.set_ylabel('AUC for each factor')\n",
    "\n",
    "for i, txt in enumerate(k):\n",
    "    label = txt[1][0]\n",
    "    if (y[i] < 0.7):\n",
    "        ax.annotate(label, (x[i], y[i]),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each assay, count positives in train\n",
    "results_dict = {}\n",
    "\n",
    "\n",
    "for (assay, res) in assay_dict.items():\n",
    "    if (not np.isnan(res['AUC'])):\n",
    "        x = matrix3[:,assaymap[assay]]\n",
    "        filtered = x[np.where(x >= 0)[0]]\n",
    "\n",
    "        sum_ = np.sum(train_data[\"y\"][filtered,:])\n",
    "        results_dict[assay] = (sum_, res['AUC'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macroAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = [v[0] for (k, v) in results_dict.items()]\n",
    "y = [v[1] for (k, v) in results_dict.items()]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "ax.set_xlabel('Number of positive examples for factor')\n",
    "ax.set_ylabel('AUC for each factor')\n",
    "ax.set_xscale('symlog')\n",
    "\n",
    "for i, txt in enumerate(results_dict.items()):\n",
    "    label = txt[0]\n",
    "    if (y[i] < 0.6 or x[i]>400000):\n",
    "        ax.annotate(\"%s: %i\" % (label, x[i]), (x[i], y[i]),\n",
    "        textcoords='offset points', ha='right', va='bottom',\n",
    "        bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n",
    "        arrowprops=dict(arrowstyle = '->', connectionstyle='arc3,rad=0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "- 96 TFs test GM12878 0.8819470290234287\n",
    "- 96 TFS test K562    0.8340156671491048\n",
    "- 96 TFS test K562 with filtering 0.7928056830435212\n",
    "- 96 TFS test K562 (One hot encoding) 0.8608675037689738 (seems to help some)\n",
    "\n",
    "\n",
    "\n",
    "Does it help to use \"one hot\" encoding? (yes)\n",
    "Remove TFs with too few positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/data/akmorrow/epitome_data/saved_models/test_model_full_2.ckpt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model  = MLP(4, [100, 100, 100, 50], \n",
    "            tf.tanh, \n",
    "            train_data, \n",
    "            valid_data, \n",
    "            test_data, \n",
    "            [],\n",
    "            gen_from_peaks, \n",
    "            matrix,\n",
    "            assaymap,\n",
    "            cellmap,\n",
    "            shuffle_size=2, \n",
    "            radii=[1,3,10,30])\n",
    "\n",
    "model.restore('/data/akmorrow/epitome_data/saved_models/model__2019_04_01__14_48.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load in all cell types for evaluation (64 cell types)\n",
    "all_matrix, all_cellmap, all_assaymap = get_assays_from_feature_file(feature_path=feature_path,eligible_assays = list(assaymap),\n",
    "                                  eligible_cells = None, min_cells_per_assay = 2, min_assays_per_cell=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_celltype = \"A549\"\n",
    "\n",
    "eval_cell_types = list(cellmap).copy()\n",
    "\n",
    "# if test_celltype is in eval_cell_types, replace it with something else\n",
    "if (test_celltype in eval_cell_types):\n",
    "    if (test_celltype == \"PANC-1\"):\n",
    "        new_eval_celltype = \"NT2-D1\" # TODO AM 4/1/2019 maybe don't hardcode\n",
    "    else:\n",
    "        new_eval_celltype = \"PANC-1\" # TODO AM 4/1/2019 maybe don't hardcode\n",
    "\n",
    "    print(\"removing %s from eval_celltypes and replacing with %s\" % (test_celltype, new_eval_celltype))\n",
    "    eval_cell_types.remove(test_celltype)\n",
    "    eval_cell_types.append(new_eval_celltype)\n",
    "\n",
    "_, iter_ = generator_to_one_shot_iterator(gen_from_peaks(test_data, \n",
    "                                               [test_celltype], \n",
    "                                               eval_cell_types,\n",
    "                                               all_matrix,\n",
    "                                               assaymap,\n",
    "                                               all_cellmap,\n",
    "                                               radii = model.radii, mode = Dataset.TEST),\n",
    "                                                   model.batch_size, 1, model.prefetch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds, truth, assay_dict, microAUC, macroAUC = model.test_from_generator(test_data[\"y\"].shape[1], iter_, log=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_total(y_true, y_prob, n_bins):\n",
    "    bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "\n",
    "    # In sklearn.calibration.calibration_curve,\n",
    "    # the last value in the array is always 0.\n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    return np.bincount(binids, minlength=len(bins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_assaymap = list(assaymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# only these two lines are calibration curves\n",
    "for i in range(truth.shape[1]):\n",
    "    logreg_y, logreg_x = calibration_curve(truth[:,i], preds[:,i], n_bins=10)\n",
    " \n",
    "    if (not np.isnan(assay_dict[list_assaymap[i+1]][\"AUC\"])): # test cell type does not have all factors!\n",
    "        plt.plot(logreg_x,logreg_y, marker='o', linewidth=1, label=list_assaymap[i+1])\n",
    "\n",
    "        \n",
    "# reference line, legends, and axis labels\n",
    "line = mlines.Line2D([0, 1], [0, 1], color='black')\n",
    "transform = ax.transAxes\n",
    "line.set_transform(transform)\n",
    "ax.add_line(line)\n",
    "fig.suptitle('Calibration plot for for A549 test regions')\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('True probability in each bin')\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          ncol=2, fancybox=True, shadow=True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EpitomeEnv_c76",
   "language": "python",
   "name": "epitomeenv_c76"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

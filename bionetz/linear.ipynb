{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dna_encoder(seq, bases='ACTG'):\n",
    "    # one-hot-encoding for sequence data\n",
    "    # enumerates base in a sequence\n",
    "    indices = map(\n",
    "        lambda x: bases.index(x) if x in bases else -1,\n",
    "        seq)\n",
    "    # one extra index for unknown\n",
    "    eye = np.eye(len(bases) + 1)\n",
    "    return eye[indices].astype(np.float32)\n",
    "\n",
    "def np_sigmoid(x):\n",
    "    # logistic sigmoid function\n",
    "    return 1 / (1 + np.e**-x)\n",
    "\n",
    "def tf_dna_encoder(seq, bases='ACTG'):\n",
    "    # wraps `dna_encoder` with a `py_func`\n",
    "    return tf.py_func(dna_encoder, [seq, bases], [tf.float32])[0]\n",
    "\n",
    "\n",
    "def dataset_input_fn(filenames,\n",
    "                     buffer_size=10000,\n",
    "                     batch_size=32,\n",
    "                     num_epochs=20,\n",
    "                     ):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    \n",
    "    # Use `tf.parse_single_example()` to extract data from a `tf.Example`\n",
    "    # protocol buffer, and perform any additional per-record preprocessing.\n",
    "    def parser(record):\n",
    "        keys_to_features = {\n",
    "            \"sequence\": tf.FixedLenFeature((), tf.string),\n",
    "            \"atacCounts\": tf.FixedLenFeature((1000,), tf.int64),\n",
    "            \"Labels\": tf.FixedLenFeature((1,), tf.int64),\n",
    "        }\n",
    "        parsed = tf.parse_single_example(record, keys_to_features)\n",
    "\n",
    "        # Perform additional preprocessing on the parsed data.\n",
    "        seq = tf_dna_encoder(parsed[\"sequence\"])\n",
    "        seq = tf.reshape(seq, [1000, 5])\n",
    "\n",
    "        # add more here if needed\n",
    "        return {'seq': seq, 'atac': parsed[\"atacCounts\"]}, parsed[\"Labels\"]\n",
    "    \n",
    "    # Use `Dataset.map()` to build a pair of a feature dictionary and a label\n",
    "    # tensor for each example.\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    # `features` is a dictionary in which each value is a batch of values for\n",
    "    # that feature; `labels` is a batch of labels.\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyper-parameters\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-3\n",
    "LOGGING_FREQUENCY = 100\n",
    "\n",
    "# reset default graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# import data as a shuffle-batch iterator\n",
    "# https://www.tensorflow.org/programmers_guide/datasets\n",
    "filenames = glob.glob('../../deleteme/CEBPB-A549-hg38.txt/part-r-*')\n",
    "features, labels = dataset_input_fn(filenames,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic-regression sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define symbolic inputs (see previous cell)\n",
    "sy_seq_n = tf.cast(features['seq'], tf.float32)\n",
    "sy_atac_n = tf.cast(features['atac'], tf.float32)\n",
    "sy_label_n = tf.cast(labels, tf.float32)\n",
    "\n",
    "# concatenate one-hot encoded seq with atac counts\n",
    "# sy_input_n = tf.concat([sy_seq_n, tf.expand_dims(sy_atac_n, axis=-1)], axis=-1)\n",
    "\n",
    "# only use sequence data\n",
    "# sy_input_n = sy_seq_n\n",
    "\n",
    "# only use atac data\n",
    "sy_input_n = sy_atac_n\n",
    "\n",
    "# flatten input tensor data\n",
    "sy_input_n = tf.contrib.layers.flatten(sy_input_n)\n",
    "\n",
    "# entering neural-network\n",
    "sy_net_n = sy_input_n\n",
    "\n",
    "# multi-layer perceptron\n",
    "sy_net_n = tf.layers.dense(sy_net_n, units=128)\n",
    "sy_net_n = tf.nn.relu(sy_net_n)\n",
    "sy_net_n = tf.layers.dense(net, units=64)\n",
    "sy_net_n = tf.nn.relu(sy_net_n)\n",
    "\n",
    "# exit neural-network to logits\n",
    "sy_logit_n = tf.layers.dense(sy_net_n, units=1, activation=None)\n",
    "\n",
    "# positively weighted loss\n",
    "POS_WEIGHT = 2\n",
    "\n",
    "# optimizer configuration\n",
    "sy_loss = tf.reduce_mean(\n",
    "    tf.nn.weighted_cross_entropy_with_logits(\n",
    "        logits=sy_logit_n,\n",
    "        targets=sy_label_n,\n",
    "        pos_weight=POS_WEIGHT))\n",
    "\n",
    "# sy_loss = tf.losses.sigmoid_cross_entropy(\n",
    "#     multi_class_labels=sy_label_n,\n",
    "#     logits=sy_logit_n)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op = optimizer.minimize(sy_loss)\n",
    "\n",
    "# define logging metrics\n",
    "sy_accuracy = tf.reduce_mean(tf.cast(\n",
    "    tf.equal(x=sy_label_n, y=tf.round(tf.nn.sigmoid(sy_logit_n))),\n",
    "    dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss=0.9268, accuracy=0.6875\n",
      "pred:  ------x-----x---x-------------------------------------------x---\n",
      "label: -x----x-----xx-x-----x-----xx-xx----x----x--x----xxx-x---xxxxx--\n",
      "iteration 100: loss=0.8543, accuracy=0.7656\n",
      "pred:  -x---------x------------------------------------------x---------\n",
      "label: ----x-x----xx---xx-x---x--------x----x----x----xx-----x-x----x--\n",
      "iteration 200: loss=0.9145, accuracy=0.7031\n",
      "pred:  -------------------------x--------------------------------------\n",
      "label: -x--------xx--x-------xx-xx----xx-xx-x-----x--x------x---xx--x-x\n",
      "iteration 300: loss=0.9463, accuracy=0.6562\n",
      "pred:  --------------------------------------------------------------xx\n",
      "label: --xx--x--x-x-x----xxx-xx------xx-----xx---x-xx-x-------xx--x--xx\n",
      "iteration 400: loss=0.9319, accuracy=0.6562\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: -x---x--------x-x----x-----x-x-x-x--x--x---xxxx-x-x-x--x----xxx-\n",
      "iteration 500: loss=0.8741, accuracy=0.7344\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: --x-xx---x---x-x--x------------xx--------x---xx-----x-x-x---xx--\n",
      "iteration 600: loss=0.8853, accuracy=0.7188\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: ---xx-x---x----x--x----------xxx-x---x-x------x---xxx-------x--x\n",
      "iteration 700: loss=0.8986, accuracy=0.7188\n",
      "pred:  x-----------------------------x--x-------------------------x----\n",
      "label: x--xx------------x---x-x-xxxx-x-xxx----x----xx----x-----xx-x--x-\n",
      "iteration 800: loss=0.8148, accuracy=0.8438\n",
      "pred:  -----xx-----------x----------------xx----------x-----------x----\n",
      "label: --x--xx---x--x----x-------x---x--x-xx------x---xx---x------x---x\n",
      "iteration 900: loss=0.8813, accuracy=0.7344\n",
      "pred:  ---------x-----------------x---------------x-x------------------\n",
      "label: ---xx----xx-x-xx--x--x--xxx--xxx-----x-----x-x--------x---------\n",
      "iteration 1000: loss=0.8884, accuracy=0.7188\n",
      "pred:  --------x---x-------------------------------------------------x-\n",
      "label: -x--xxx-x-x-xx-x-x------x------x--x-x---x--------x-------xxx--xx\n",
      "iteration 1100: loss=0.8695, accuracy=0.7344\n",
      "pred:  -------------------------x------------------x------------x------\n",
      "label: x------xx---x----xxx--x--x----x-xxx-x---x---x-xx-------x-x------\n",
      "iteration 1200: loss=0.7668, accuracy=0.8750\n",
      "pred:  --------------------------x-------------------------------------\n",
      "label: ---------------------x----x---------xx------x----x----x----x-x--\n",
      "iteration 1300: loss=0.8101, accuracy=0.8125\n",
      "pred:  --------------------x-------------------------------------------\n",
      "label: -x--x--------------xx--x------------xx-xx-------x-------xxx-----\n",
      "iteration 1400: loss=0.8241, accuracy=0.7812\n",
      "pred:  ------------------x--x---------------------x--------------------\n",
      "label: xx-----------xx---x----x---x-xx-x--x---x---x--x-------x---------\n",
      "iteration 1500: loss=0.8273, accuracy=0.7812\n",
      "pred:  --------------------------x------------------x------------------\n",
      "label: -x-------x--x---xx---xxx----------x--------x-xx---x---x---------\n",
      "iteration 1600: loss=0.8960, accuracy=0.7031\n",
      "pred:  ----------x------x------x-------x-------------------------------\n",
      "label: x----x-----xxx-x-x-x----xx-xx---x-x-----------------xx-xxxxx----\n",
      "iteration 1700: loss=0.8401, accuracy=0.7656\n",
      "pred:  -------x----------------------------------------------------x---\n",
      "label: -x-----x--x------x----x--xxx--------xx--x----------x------xxxxx-\n",
      "iteration 1800: loss=0.9346, accuracy=0.6562\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: -xxxx----------x--x-x-x--xx---x-------x----x----x-x-xx----xxx-xx\n",
      "iteration 1900: loss=0.8650, accuracy=0.7500\n",
      "pred:  -------------------------------------------------x--------------\n",
      "label: x--x-x--x------x--xx-x-x--x--x----x-----x---x----x--------x-x---\n",
      "iteration 2000: loss=0.9093, accuracy=0.6719\n",
      "pred:  -----------------------------x----------------------------------\n",
      "label: ----x-x--xxx-xx--x-x---xxx--x----xx-x------x----------x--x-x----\n",
      "iteration 2100: loss=0.8290, accuracy=0.7812\n",
      "pred:  ---------------x------------------------------x----------------x\n",
      "label: ---x-x---x---x-x-x-------xxx-----------------------xx--x-x-x---x\n",
      "iteration 2200: loss=0.8624, accuracy=0.7500\n",
      "pred:  ----------------------x-----------------x-----------------------\n",
      "label: -xxx-----------x-x--x-x--x--------x-x---x-----xxx----------xxx-x\n",
      "iteration 2300: loss=0.9285, accuracy=0.6875\n",
      "pred:  ---xx------------------------------------x----x-----------------\n",
      "label: x--xxx-----x---xx-x--x-x-x-x--xx--x-x-x--x-x--x------x----x--xx-\n",
      "iteration 2400: loss=0.8368, accuracy=0.7812\n",
      "pred:  --x---------------x------------------------------x---------x----\n",
      "label: --x------------xx-x---xxx--xx---------------x--xxx---x---xxx---x\n",
      "iteration 2500: loss=0.9495, accuracy=0.6406\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: -xx--x-x--x------x-x-xx----xx-x--------xx--x-x---x--x-x--xx-xx--\n",
      "iteration 2600: loss=0.8302, accuracy=0.7969\n",
      "pred:  ------------------------x---x-----x---x-------------------x-----\n",
      "label: xx-x--xx----x---x---x---x---xx----x---xx---x--x-------x---x-----\n",
      "iteration 2700: loss=0.8128, accuracy=0.7969\n",
      "pred:  x--------x-----------------------x------------------------------\n",
      "label: x--x----------------x-----x----x-x-x------x-x--x--x-----xx---x--\n",
      "iteration 2800: loss=0.9224, accuracy=0.6875\n",
      "pred:  --x---------x---------------x----------x--------------x---------\n",
      "label: --xxx--x---xx----x---x-x-----------x-x-x-xxxx-------xxxxx-x-x---\n",
      "iteration 2900: loss=0.9805, accuracy=0.6094\n",
      "pred:  ----x--------x--------------------------------x-----------------\n",
      "label: x---xxx---x-xxxx-x-x----xxxxxx-x---x-----xx----x---xxx---------x\n",
      "iteration 3000: loss=0.8693, accuracy=0.7188\n",
      "pred:  ---------------------------------x-----------------------x------\n",
      "label: -xxx-----x-x---x-----x-xx-x-x--x-x-x------x--------x------x----x\n",
      "iteration 3100: loss=1.0185, accuracy=0.5625\n",
      "pred:  ----------------------------------------x---------xx------------\n",
      "label: x--x--x-x------x---x----------xx--x-x-xxxxxx-xx-xxx-x-x-xxx-xx-x\n",
      "iteration 3200: loss=0.9719, accuracy=0.6406\n",
      "pred:  ----------------------------------x-------x--------------------x\n",
      "label: --xxxx--x-----x---x-x---x-x-x---xxx----x--x--x---xx---xxxxxx---x\n",
      "iteration 3300: loss=0.8717, accuracy=0.7188\n",
      "pred:  -----x-------x--------------------------------------------------\n",
      "label: ---x-x-xxx--xx-------x---------xx---x--x-x--x-xx--x--xx-------x-\n",
      "iteration 3400: loss=0.8541, accuracy=0.7500\n",
      "pred:  --x-------------------------------------------------------------\n",
      "label: -xx-----x--x-----xx--------------x----xxx-xxx-----x---x-x------x\n",
      "iteration 3500: loss=0.7456, accuracy=0.8594\n",
      "pred:  -----x------x----------------------------------------x-------x-x\n",
      "label: ----xx------x--x---------x-------x---x----x------x---x-----xxx-x\n",
      "iteration 3600: loss=0.8512, accuracy=0.7500\n",
      "pred:  ----------------------------------------------------------------\n",
      "label: ---------------xxx-----xx-xx-x----x---------------x-x-x-x--xxx--\n",
      "iteration 3700: loss=0.7907, accuracy=0.8438\n",
      "pred:  -x--x--x--------------------------------------------------------\n",
      "label: -x--x--xx---x--xx--x---xx--x----------x----x--------------------\n",
      "iteration 3800: loss=0.8817, accuracy=0.7031\n",
      "pred:  ------------------------------x-----x---------------------------\n",
      "label: --x---x-xx-xxx-x-xx---xx-xx---xx----x----x--x---------x-----x---\n",
      "iteration 3900: loss=0.8745, accuracy=0.7344\n",
      "pred:  ---------------------------x-----------------x------------------\n",
      "label: -----x-xx-x---x-xx--------xx---x-----x-xx-x-xx--x----x-----x----\n",
      "iteration 4000: loss=0.8603, accuracy=0.7500\n",
      "pred:  -----------------------------x----------------------------------\n",
      "label: xx-------x------------xx-----xxx-x-x-xx---x-------------x--xxx--\n",
      "iteration 4100: loss=0.9308, accuracy=0.6562\n",
      "pred:  ----------------------------------x-----------------------------\n",
      "label: xx----x-x----x---------xxx--xx-x-xxx--x--xx-----x---x----xx-x--x\n",
      "iteration 4200: loss=0.8908, accuracy=0.7188\n",
      "pred:  -------x-------x--------x---------x----x-x----------------------\n",
      "label: x----xxxx-----xxx----x--x-xxxx----x---xx-xx----xx----x---x-----x\n",
      "iteration 4300: loss=0.9148, accuracy=0.6875\n",
      "pred:  ---------------------------------------------x------x-----------\n",
      "label: ---x-----x--xx-------x--xx--xx--x--------xxx-x------xxx-x-xx-xx-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4400: loss=0.8233, accuracy=0.7656\n",
      "pred:  -----x---------------------------------x--------x---------------\n",
      "label: -----x--xx-----x--------x----xx---xx---x----xx-----x---x-x----x-\n",
      "iteration 4500: loss=0.9515, accuracy=0.6250\n",
      "pred:  ------------x-----x------------------x--------------------------\n",
      "label: -xx-x-x--xxxxx----x-x-x-----xx-xx---xxx-xx-x------xx----x--x---x\n",
      "iteration 4600: loss=0.8345, accuracy=0.7812\n",
      "pred:  ----------------------------x------------------------------x----\n",
      "label: --------------------------x-x-x--x-----xx-xx--xx-x-xx-x----x---x\n",
      "iteration 4700: loss=0.8497, accuracy=0.7500\n",
      "pred:  -------------------------------x--x------------x----------------\n",
      "label: x-------xx-x--xx---x--x-----x-xx-xxx-x----------------------x--x\n",
      "iteration 4800: loss=0.8070, accuracy=0.7969\n",
      "pred:  ---------------------------------------------------------------x\n",
      "label: ---xxx-x--------x-----x-x--x-----x-------x--------x------x--x--x\n",
      "iteration 4900: loss=0.8680, accuracy=0.7500\n",
      "pred:  -----x---------x-------x-----------------------------------x----\n",
      "label: ---x-x--x-xx--xx----xx-xx----------------x---x-x-xxxx------x-x--\n",
      "iteration 5000: loss=0.9622, accuracy=0.6406\n",
      "pred:  --------x--------------------x----------------------------------\n",
      "label: -x-x--x-x-----x--x-xx-xx-x-xxxxxx--------------x---x---xxxx-x-x-\n",
      "iteration 5100: loss=0.8607, accuracy=0.7656\n",
      "pred:  -------------x----------x---------------x-----------------------\n",
      "label: ----------x--x---x-xx---xxx---------x---xx-x---xx---x-x-------xx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-8881170d497c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msy_logit_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy_label_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msy_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# log the cross-entropy loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mLOGGING_FREQUENCY\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    519\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    890\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    893\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alexyku/anaconda3/envs/python2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# begin the training loop\n",
    "with tf.train.MonitoredTrainingSession() as sess:\n",
    "    iteration = 0\n",
    "    while not sess.should_stop():\n",
    "        fetches = [sy_logit_n, sy_label_n, sy_loss, sy_accuracy, train_op]\n",
    "        logit, label, loss, accuracy, _ = sess.run(fetches)\n",
    "        # log the cross-entropy loss and accuracy\n",
    "        if iteration % LOGGING_FREQUENCY == 0:\n",
    "            print('iteration %i: loss=%.4f, accuracy=%.4f' % (iteration, loss, accuracy))\n",
    "            prob = np_sigmoid(logit).flatten()\n",
    "            def binary_print(binary_seq):\n",
    "                return ''.join(['x' if x == 1 else '-' for x in binary_seq])\n",
    "            print('pred:  %s' % binary_print(np.round(prob).astype(np.int32)))\n",
    "            print('label: %s' % binary_print(label.flatten().astype(np.int32)))\n",
    "        iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

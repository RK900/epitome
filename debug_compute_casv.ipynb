{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipynb in /home/eecs/rvkoodli/miniconda3/envs/EpitomeEnv3/lib/python3.6/site-packages (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epitome.models import *\n",
    "from epitome.functions import *\n",
    "from epitome.generators import *\n",
    "from epitome.dataset import *\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from ipynb.fs.defs.debug_score_matrix import WrapperModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapperModel(EpitomeModel):\n",
    "    def score_matrix(self, accessibility_peak_matrix, regions):\n",
    "        \"\"\" Runs predictions on a matrix of accessibility peaks, where columns are samples and\n",
    "        rows are regions from regions_peak_file. rows in accessilibility_peak_matrix should matching\n",
    "\n",
    "        :param numpy.matrix accessilibility_peak_matrix:  of (samples by genomic regions)\n",
    "        :param str regions: either narrowpeak or bed file containing regions to score, OR a pyranges object\n",
    "            with columns [Chomosome, Start, End, idx]. Index matches each genomic region to a row in\n",
    "            accessilibility_peak_matrix. In both cases, number of regions Should\n",
    "            match rows in accessilibility_peak_matrix\n",
    "\n",
    "        :return: 3-dimensional numpy matrix of predictions: sized (samples by regions by ChIP-seq targets)\n",
    "        :rtype: numpy matrix\n",
    "        \"\"\"\n",
    "\n",
    "        conversionObject = RegionConversion(self.dataset.regions, regions)\n",
    "\n",
    "        results = []\n",
    "        # print(accessibility_peak_matrix.shape)\n",
    "        matrix, indices = conversionObject.get_binary_vector(vector = accessibility_peak_matrix[0,:])\n",
    "        gen = load_data_runtime(data=self.dataset.get_data(Dataset.ALL),\n",
    "                 label_cell_types=self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types=self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix=self.dataset.matrix,\n",
    "                 targetmap=self.dataset.targetmap,\n",
    "                 cellmap=self.dataset.cellmap,\n",
    "                 radii = self.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 indices = indices,\n",
    "                 return_feature_names=False)\n",
    "\n",
    "        to_stack = load_data_no_label_mask(data=self.dataset.get_data(Dataset.ALL),\n",
    "                 label_cell_types=self.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types=self.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix=self.dataset.matrix,\n",
    "                 targetmap=self.dataset.targetmap,\n",
    "                 cellmap=self.dataset.cellmap,\n",
    "                 radii = self.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 indices = indices,\n",
    "                 return_feature_names=True)\n",
    "\n",
    "        gen_to_list = list(gen())\n",
    "        to_stack = list(to_stack())\n",
    "        gen_to_list = np.array(gen_to_list)\n",
    "\n",
    "        # reshape to n_regions [from regions] x nassays [acc dim 1] x n_samples\n",
    "        radii = self.radii\n",
    "        \n",
    "        set_trace()\n",
    "\n",
    "        stacked = np.stack([to_stack] * accessibility_peak_matrix.shape[0], axis=0)\n",
    "        names = stacked[:, :, 1]\n",
    "        to_stack = stacked[:, :, 0]\n",
    "        to_stack = np.expand_dims(to_stack, axis=-1)\n",
    "\n",
    "        same_size = accessibility_peak_matrix.shape[1] == len(conversionObject.joined.idx_base)\n",
    "\n",
    "        if not same_size:\n",
    "            added_indices = []\n",
    "            old_idx, counter, old_i = 0, 0, 0\n",
    "            indices_to_merge = []\n",
    "            for ctr, (i, i_base) in enumerate(zip(conversionObject.joined.idx, conversionObject.joined.idx_base)):\n",
    "                if i_base == -1:\n",
    "                    continue\n",
    "                if i != old_i:\n",
    "                    indices_to_merge.append((old_idx, counter))\n",
    "                    old_idx = counter\n",
    "                added_indices.append(accessibility_peak_matrix[:, i])\n",
    "                counter += 1\n",
    "                old_i = i\n",
    "            indices_to_merge.append((old_idx, len(conversionObject.joined.idx)))\n",
    "            \n",
    "            a = np.stack(added_indices)\n",
    "        else:\n",
    "            a = np.transpose(accessibility_peak_matrix, axes=[1, 0])\n",
    "        \n",
    "        \n",
    "        a = a[:, None, :]\n",
    "        \n",
    "        set_trace()\n",
    "        \n",
    "        out = compute_casv(gen_to_list, a, radii)\n",
    "        \n",
    "        set_trace()\n",
    "\n",
    "        casv_len = out.shape[1]\n",
    "        num_cells = out.shape[3]\n",
    "        num_regions = out.shape[0]\n",
    "        num_celltypes = out.shape[2]\n",
    "        num_targets = len(self.dataset.targets) if 'DNase' in self.dataset.targets else len(self.dataset.targets) + 1\n",
    "\n",
    "        print(out)\n",
    "        print(out.shape)\n",
    "        # assert False\n",
    "\n",
    "        for region in range(num_regions):\n",
    "            for cell in range(num_cells):\n",
    "\n",
    "                selected_gen = to_stack[cell, region, :]\n",
    "                selected_casv = out[region, :, :, cell]\n",
    "\n",
    "                len_feats_per_celltype = int(selected_gen[0].shape[0] / num_celltypes) # 24 / 2 = 12\n",
    "\n",
    "                old_sg = selected_gen\n",
    "\n",
    "                for celltype in range(num_celltypes):\n",
    "                    # print(celltype)\n",
    "                    idx = len_feats_per_celltype * celltype\n",
    "                    casv_cell = selected_casv[:, celltype]\n",
    "                    # print(idx + 4, idx + len_feats_per_celltype)\n",
    "                    # print(names)\n",
    "                    # print(num_targets)\n",
    "                    selected_gen[0][idx + num_targets : idx + len_feats_per_celltype] = casv_cell\n",
    "                    # assert np.any()\n",
    "\n",
    "        results = []\n",
    "        for c in range(num_cells):\n",
    "            for r in range(num_regions):\n",
    "                results.append(self._predict(to_stack[c, r, :][0][None, :]))\n",
    "        \n",
    "        \n",
    "        results = np.stack(results)\n",
    "        results = results.reshape((gen_to_list.shape[1], gen_to_list.shape[0])) # 4 x 5\n",
    "\n",
    "        if not same_size:\n",
    "            final = []\n",
    "            final = np.empty((accessibility_peak_matrix.shape[0], accessibility_peak_matrix.shape[1], 1))\n",
    "            final.fill(np.nan)\n",
    "            for tup in indices_to_merge:\n",
    "                final[:, 0, 0] = np.mean(results[:, tup[0]:tup[1]], axis=1)\n",
    "            \n",
    "            # final = np.stack(final)\n",
    "            # final = final.reshape((accessibility_peak_matrix.shape[0], accessibility_peak_matrix.shape[1], 1))\n",
    "            return final\n",
    "        results = results.reshape((results.shape[0], results.shape[1], 1))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_casv(m1, m2, radii, indices= None):\n",
    "    '''\n",
    "    Computes CASV between two matrices. CASV indiciates how similar\n",
    "    two binary matrices are to eachother. m1 and m2 should have the\n",
    "    same number of rows and columns, where rows indicate regions and\n",
    "    columns indicate the assays used to compute the casv (ie DNase-seq, H3K27ac)\n",
    "    :param np.matrix m1: 2D or 3D numpy matrix 2D shape (nregions x (nassays x ncelltypes))\n",
    "      where 2nd dimension is blocked by cells (i.e. cell1assay1, cell1assay2, cell2assay1, cell2assay2)\n",
    "      OR 3D: (nregions x nassays x ncells)\n",
    "    :param np.matrix m2: 3D numpy matrix shape (nregions x nassays x nsamples)\n",
    "    :param radii: list of radii to access surrounding region\n",
    "    :param indices: indices on 0th axis of m1 and m2 to compute casv for\n",
    "    :return numpy matrix of size (len(indices) x CASV dimension x ncelltypes x ncells)\n",
    "    '''\n",
    "\n",
    "    if indices is None:\n",
    "        indices = range(m1.shape[0])\n",
    "\n",
    "    # if only one sample, extend m2 along 2nd axis\n",
    "    if len(m2.shape) == 2:\n",
    "        m2 = m2[:,:,None]\n",
    "\n",
    "    # if needed, reshape m1 to put all assay/train cells on the last axis\n",
    "    if len(m1.shape) == 3:\n",
    "      ncells = m1.shape[-1]\n",
    "      m1 = m1.reshape(m1.shape[0],m1.shape[1]*m1.shape[2])\n",
    "    else:\n",
    "      denom = 1 if m2.shape[1]==0 else m2.shape[1]\n",
    "      ncells = int(m1.shape[-1]/denom)\n",
    "\n",
    "    if m2.shape[1] == 0:\n",
    "      # in this case, there is no CASV to compute, so we just return\n",
    "      return np.zeros((len(indices),0, ncells,m2.shape[-1]))\n",
    "\n",
    "    print(m1.shape, m2.shape)\n",
    "    assert m1.shape[0] == m2.shape[0]\n",
    "    # verify number of assays match\n",
    "    assert m2.shape[1] == m1.shape[-1]/ncells\n",
    "    # print('HERE')\n",
    "    \n",
    "#     set_trace()\n",
    "\n",
    "    def f(i):\n",
    "        \n",
    "#         set_trace()\n",
    "        # get indices for each radius in radii\n",
    "        radius_ranges = list(map(lambda x: get_radius_indices(radii, x, i, m1.shape[0]), range(len(radii))))\n",
    "\n",
    "        if len(radius_ranges) > 0:\n",
    "            radius_indices = np.concatenate(radius_ranges)\n",
    "\n",
    "            # data from known cell types (m1 portion)\n",
    "            m1_slice = m1[radius_indices, :]\n",
    "            m2_slice = np.repeat(m2[radius_indices, :, :],axis=1, repeats = ncells)\n",
    "            \n",
    "\n",
    "            # shape: radius size x (nassaysxncells) by nsamples\n",
    "            pos = (m1_slice.T*m2_slice.T).T\n",
    "#             agree = (m1_slice.T == m2_slice.T).T\n",
    "\n",
    "            # split pos and agree arrays to create new dimension for ncells\n",
    "            # the new dimension will be 4D: (radius x nassays x ncells x nsamples)\n",
    "            pos = np.stack(np.split(pos, ncells, axis=1), axis=2)\n",
    "#             agree = np.stack(np.split(agree, ncells, axis=1), axis=2)\n",
    "            \n",
    "            # get indices to split on. remove last because it is empty\n",
    "            split_indices = np.cumsum([len(i) for i in radius_ranges])[:-1]\n",
    "            # slice arrays by radii\n",
    "            pos_arrays = np.split(pos, split_indices, axis= 0 )\n",
    "#             agree_arrays = np.split(agree, split_indices, axis = 0)\n",
    "\n",
    "            # average over the radius (0th axis)\n",
    "            tmp1 = list(map(lambda x: np.average(x, axis = 0), pos_arrays)) # this line is problematic\n",
    "            # final concatenation combines agree, nassays, and radii on the 0th axis\n",
    "            # this axis is ordered by (1) pos/agree, then (2) radii, then (2) n assays.\n",
    "            # See ordering example when there are 2 radii (r1, r2):\n",
    "            # - pos: r1, nassays | pos: r2, nassays | agree: r1: nassays | agree: r1: nassays\n",
    "            tmp = np.concatenate(tmp1, axis=0)\n",
    "            return tmp\n",
    "        else:\n",
    "            # no radius, so no similarities. just an empty placeholder\n",
    "            # shaped with the number of cells (last dim of m1)\n",
    "            return np.zeros((0,ncells,m2.shape[-1]))\n",
    "\n",
    "    # for every region of interest\n",
    "    # TODO: maybe something more efficient?\n",
    "\n",
    "    # set_trace()\n",
    "    tmp = []\n",
    "    for i in indices:\n",
    "        tmp.append(f(i))\n",
    "    \n",
    "    return np.stack(tmp)\n",
    "#     return np.stack([f(i) for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data,\n",
    "                 label_cell_types,  # used for labels. Should be all for train/eval and subset for test\n",
    "                 eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 matrix,\n",
    "                 targetmap,\n",
    "                 cellmap,\n",
    "                 radii,\n",
    "                 similarity_targets = ['DNase'],\n",
    "                 mode = Dataset.TRAIN,\n",
    "                 similarity_matrix = None,\n",
    "                 indices = None,\n",
    "                 return_feature_names = False,\n",
    "                 **kwargs):\n",
    "    \"\"\"\n",
    "    Takes Deepsea data and calculates distance metrics from cell types whose locations\n",
    "    are specified by label_cell_indices, and the other cell types in the set. Label space is only one cell type.\n",
    "    :param data: dictionary of matrices. Should have keys x and y. x contains n by 1000 rows. y contains n by 919 labels.\n",
    "    :param label_cell_types: list of cell types to be rotated through and used as labels (subset of eval_cell_types)\n",
    "    :param eval_cell_types: list of cell types to be used in evaluation (includes label_cell_types)\n",
    "    :param matrix: matrix of celltype, target positions\n",
    "    :param targetmap: map of column target positions in matrix\n",
    "    :param cellmap: map of row cell type positions in matrix\n",
    "    :param radii: radii to compute similarity distances from\n",
    "    :param similarity_targets: list of targets used to measure cell type similarity (default is DNase-seq)\n",
    "    :param mode: Dataset.TRAIN, VALID, TEST or RUNTIME\n",
    "    :param similarity_matrix: matrix with shape (len(similarity_targets), genome_size) containing binary 0/1s of peaks for similarity_targets\n",
    "    to be compared in the CASV.\n",
    "    :param indices: indices in genome to generate records for.\n",
    "    :param return_feature_names: boolean whether to return string names of features\n",
    "    :param kwargs: kargs\n",
    "\n",
    "    :returns: generator of data with three elements:\n",
    "        1. record features\n",
    "        2. record labels for a given cell type\n",
    "        3. 0/1 mask of labels that have validation data. For example, if this record is for celltype A549,\n",
    "        and A549 does not have data for ATF3, there will be a 0 in the position corresponding to the label space.\n",
    "    \"\"\"\n",
    "\n",
    "    # reshape similarity_matrix to a matrix if there is only one target\n",
    "    if similarity_matrix is not None:\n",
    "        if len(similarity_matrix.shape) == 1:\n",
    "            similarity_matrix = similarity_matrix[None,:]\n",
    "\n",
    "    if type(similarity_targets) is not list:\n",
    "        similarity_targets = [similarity_targets]\n",
    "\n",
    "    if len(similarity_targets) == 0 and len(radii) > 0:\n",
    "        raise ValueError(\"Cannot set radii to anything if there are no similarity assays, but found len(radii)=%i\" % len(radii))\n",
    "\n",
    "    # get indices for features. rows are cells and cols are targets\n",
    "    cellmap_idx = [cellmap[c] for c in list(eval_cell_types)]\n",
    "    feature_cell_indices = matrix[cellmap_idx,:]\n",
    "\n",
    "    # indices to be deleted. used for similarity comparison, not predictions.\n",
    "    delete_indices = np.array([targetmap[s] for s in similarity_targets]).astype(int)\n",
    "\n",
    "    # make sure no similarity comparison data is missing for all cell types\n",
    "    assert np.invert(np.any(feature_cell_indices[:,delete_indices] == -1)), \\\n",
    "        \"missing data for similarity target at %s\" % (np.where(feature_cell_indices[:,delete_indices] == -1)[0])\n",
    "\n",
    "    # names of labels that are being predicted\n",
    "    feature_targets = [a for a in list(targetmap)] # targets used as features for each evaluation cell type\n",
    "    label_targets = [a for a in feature_targets if a not in similarity_targets]\n",
    "\n",
    "    if (not isinstance(mode, Dataset)):\n",
    "        raise ValueError(\"mode is not a Dataset enum\")\n",
    "\n",
    "    if (not isinstance(indices, np.ndarray) and not isinstance(indices, list)):\n",
    "        # model performs better when there are less 0s\n",
    "        if mode == Dataset.TRAIN:\n",
    "            feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                     list(cellmap))))\n",
    "            feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "            # need to re-proportion the indices to oversample underrepresented labels\n",
    "            if (len(list(targetmap)) > 2):\n",
    "                # configure y: label matrix of ChIP for all targets from all cell lines in train\n",
    "                indices = np.concatenate([EpitomeDataset.get_y_indices_for_target(matrix, targetmap, target) for target in label_targets])\n",
    "                indices = indices[indices != -1]\n",
    "                y = data[indices, :].T\n",
    "                m = MLSMOTE(y)\n",
    "                indices = m.fit_resample()\n",
    "\n",
    "            else:\n",
    "                # single TF model\n",
    "                # get indices for DNase and chip for this mark\n",
    "                feature_indices = np.concatenate(list(map(lambda c: EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, c),\n",
    "                                                     list(cellmap))))\n",
    "\n",
    "                # chop off targets being used in similarity metric\n",
    "                not_similarity_indices = np.array([v for k,v in targetmap.items() if k not in similarity_targets])\n",
    "                TF_indices = feature_indices.reshape([len(cellmap),len(targetmap)])[:,not_similarity_indices]\n",
    "\n",
    "                TF_indices =  TF_indices[TF_indices != -1]\n",
    "                feature_indices = feature_indices[feature_indices != -1]\n",
    "\n",
    "                # sites where TF is bound in at least 2 cell line\n",
    "                positive_indices = np.where(np.sum(data[TF_indices,:], axis=0) > 1)[0]\n",
    "                indices_probs = np.ones([data.shape[1]])\n",
    "                indices_probs[positive_indices] = 0\n",
    "                indices_probs = indices_probs/np.sum(indices_probs, keepdims=1)\n",
    "\n",
    "                # If there are nans, it means there were no 0 cases.\n",
    "                # We use this for testing so models converge quickly\n",
    "                # with all ones.\n",
    "                if np.any(np.isnan(indices_probs)):\n",
    "                  print(\"Warning: no negative examples in dataset!!!\")\n",
    "                  indices_probs[:] = 1/indices_probs.shape[0]\n",
    "\n",
    "                # randomly select 10 fold sites where TF is not in any cell line\n",
    "                negative_indices = np.random.choice(np.arange(0,data.shape[1]),\n",
    "                                                    positive_indices.shape[0] * 10,\n",
    "                                                    p=indices_probs)\n",
    "                indices = np.sort(np.concatenate([negative_indices, positive_indices]))\n",
    "\n",
    "        else:\n",
    "            indices = range(0, data.shape[-1]) # not training mode, set to all points\n",
    "\n",
    "#     set_trace()\n",
    "    \n",
    "    if (mode == Dataset.RUNTIME):\n",
    "        label_cell_types = [\"PLACEHOLDER_CELL\"]\n",
    "        if similarity_matrix is None:\n",
    "            raise Exception(\"similarity_matrix must be defined in runtime mode\")\n",
    "        assert similarity_matrix.shape[0] == len(similarity_targets), \\\n",
    "            \"similarity_matrix is missing data for targets (should have %i rows)\" % (len(similarity_targets))\n",
    "        random_cell = list(cellmap)[0] # placeholder to get label vector length\n",
    "\n",
    "    print(\"using %s as labels for mode %s\" % (label_cell_types, mode))\n",
    "\n",
    "    # string of radii for meta data labeling\n",
    "    radii_str = list(map(lambda x: \"RADII_%i\" % x, radii))\n",
    "\n",
    "    def g():\n",
    "        \n",
    "        for i in indices: # for all records specified\n",
    "\n",
    "            for (cell) in label_cell_types: # for all cell types to be used in labels\n",
    "\n",
    "                # labels for this cell\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    label_cell_indices = EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, cell)\n",
    "\n",
    "                    # delete all indices being used in the similarity computation\n",
    "                    label_cell_indices_no_similarities = np.delete(label_cell_indices, delete_indices)\n",
    "\n",
    "                    # Copy target_index_no_similarities and turn into mask of 0/1 for whether data for this cell type for\n",
    "                    # a given label is available.\n",
    "                    target_mask = np.copy(label_cell_indices_no_similarities)\n",
    "                    target_mask[target_mask > -1] = 1\n",
    "                    target_mask[target_mask == -1] = 0\n",
    "\n",
    "                else:\n",
    "                    label_count = len(EpitomeDataset.get_y_indices_for_cell(matrix, cellmap, random_cell))-len(similarity_targets)\n",
    "\n",
    "                    # Mask and labels are all 0's because labels are missing during runtime\n",
    "                    garbage_labels = target_mask = np.zeros(label_count)\n",
    "\n",
    "\n",
    "                # get indices for targets used in similarity computation\n",
    "                # for cell types that are going to be features\n",
    "                similarity_indices = feature_cell_indices[:, delete_indices]\n",
    "\n",
    "                    \n",
    "                set_trace()\n",
    "\n",
    "                # get indices for each radius in radii\n",
    "                radius_ranges = list(map(lambda x: get_radius_indices(radii, x, i, data.shape[-1]), range(len(radii))))\n",
    "\n",
    "                if len(radius_ranges) > 0:\n",
    "                    radius_indices = np.concatenate(radius_ranges)\n",
    "\n",
    "                    cell_train_data = data[similarity_indices[:,:,None],radius_indices]\n",
    "\n",
    "                    if mode == Dataset.RUNTIME:\n",
    "\n",
    "                        pos = cell_train_data*similarity_matrix[:,radius_indices]\n",
    "                        agree = cell_train_data == similarity_matrix[:,radius_indices]\n",
    "\n",
    "                    else:\n",
    "                        cell_label_data = data[label_cell_indices[delete_indices][:,None],radius_indices]\n",
    "\n",
    "                        # remove middle dimension and flatten similarity targets\n",
    "                        pos = (cell_train_data*cell_label_data)\n",
    "#                         agree = (cell_train_data == cell_label_data)\n",
    "                        \n",
    "#                         set_trace()\n",
    "\n",
    "                    # get indices to split on. remove last because it is empty\n",
    "                    split_indices = np.cumsum([len(i) for i in radius_ranges])[:-1]\n",
    "                    # slice arrays by radii\n",
    "                    pos_arrays = np.split(pos, split_indices, axis= -1 )\n",
    "#                     agree_arrays = np.split(agree, split_indices, axis = -1)\n",
    "                    \n",
    "#                     set_trace()\n",
    "                    # NEW ITER\n",
    "\n",
    "                    similarities = np.stack(list(map(lambda x: np.average(x, axis = -1), pos_arrays)),axis=1)\n",
    "                else:\n",
    "                    # no radius, so no similarities. just an empty placeholder\n",
    "                    similarities = np.zeros((len(eval_cell_types),0,0))\n",
    "\n",
    "                # reshape similarities to flatten 1st dimension, which are the targets\n",
    "                # results in the odering:\n",
    "                ## row 1: cell 1: pos for each target and agree for each target for each radius\n",
    "                similarities = similarities.reshape(similarities.shape[0], similarities.shape[1]*similarities.shape[2])\n",
    "\n",
    "                ##### Concatenate all cell type features together ####\n",
    "                final_features = np.concatenate([data[feature_cell_indices,i], similarities],axis=1).flatten()\n",
    "\n",
    "                # mask missing data\n",
    "                f_mask = np.concatenate([feature_cell_indices!=-1,\n",
    "                                         np.ones(similarities.shape)],axis=1).flatten()\n",
    "                final_features = final_features[f_mask != 0]\n",
    "\n",
    "                if (mode != Dataset.RUNTIME):\n",
    "                    labels = data[label_cell_indices_no_similarities,i]\n",
    "\n",
    "                else: # used when just predicting\n",
    "                    # The features going into the example.\n",
    "                    labels = garbage_labels # all 0's\n",
    "\n",
    "                # append labels and targetmask\n",
    "                final= tuple([final_features, labels.astype(np.float32), target_mask.astype(np.float32)])\n",
    "\n",
    "                #### Finish appending feature labels together ####\n",
    "                if (return_feature_names):\n",
    "                    all_labels = []\n",
    "                    feature_names = []\n",
    "                    similarity_labels_agreement = ['r%i_%s' % (radius, 'agree') for radius in radii]\n",
    "#                     similarity_labels_dp = ['r%i_%s' % (radius, 'dp') for radius in radii]\n",
    "                    similarity_labels = similarity_labels_agreement\n",
    "\n",
    "                    # concatenate together feature names\n",
    "                    for j,c in enumerate(eval_cell_types):\n",
    "                        tmp = np.array(feature_targets)[feature_cell_indices[j,:] != -1]\n",
    "                        al = ['%s_%s' % (c, a) for a in tmp]\n",
    "                        sl = ['%s_%s' % (c, s) for s in similarity_labels]\n",
    "\n",
    "                        feature_names.append(al)\n",
    "                        feature_names.append(sl)\n",
    "\n",
    "                    all_labels.append(np.concatenate(feature_names))\n",
    "                    all_labels.append(['lbl_%s_%s' % (cell, a) for a in label_targets]) # of form lbl_cellline_target\n",
    "                    all_labels.append(['mask_%s_%s' % (cell, a) for a in label_targets]) # of form mask_cellline_target\n",
    "\n",
    "                    yield (final, tuple(all_labels))\n",
    "                else:\n",
    "                    yield final\n",
    "\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['HepG2', 'HeLa-S3', 'H1', 'A549'] as labels for mode Dataset.TRAIN\n",
      "using ['HepG2', 'HeLa-S3', 'H1', 'A549'] as labels for mode Dataset.VALID\n",
      "using ['K562'] as labels for mode Dataset.TEST\n",
      "(8587562,)\n",
      "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
      "| Chromosome   |     Start |       End |       idx |   Start_base |   End_base |   idx_base |\n",
      "| (category)   |   (int64) |   (int64) |   (int64) |      (int64) |    (int64) |    (int64) |\n",
      "|--------------+-----------+-----------+-----------+--------------+------------+------------|\n",
      "| chr1         |     10000 |     10300 |         0 |        10000 |      10200 |          0 |\n",
      "| chr1         |     10000 |     10300 |         0 |        10200 |      10400 |          1 |\n",
      "| chr1         |     30000 |     31200 |         1 |        30600 |      30800 |          6 |\n",
      "| chr1         |     30000 |     31200 |         1 |        30800 |      31000 |          7 |\n",
      "| chr1         |     30000 |     31200 |         1 |        31000 |      31200 |          8 |\n",
      "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
      "Unstranded PyRanges object has 5 rows and 7 columns from 1 chromosomes.\n",
      "For printing, the PyRanges was sorted on Chromosome.\n",
      "bv [0. 0. 0. 0. 0.]\n",
      "v [1. 1. 1. 1. 1.]\n",
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n"
     ]
    }
   ],
   "source": [
    "radii = [1]\n",
    "accessibility_peak_matrix = np.random.uniform(low=0., high=1., size=(4,2))\n",
    "accessibility_peak_matrix = np.ones((4, 2))\n",
    "\n",
    "eligible_cells = ['K562','HepG2','H1','A549','HeLa-S3']\n",
    "eligible_targets = ['DNase','CTCF', 'RAD21']\n",
    "\n",
    "dataset = EpitomeDataset(targets = eligible_targets,\n",
    "    cells = eligible_cells)\n",
    "\n",
    "\n",
    "model = WrapperModel(dataset,\n",
    "    test_celltypes = ['K562'])\n",
    "\n",
    "model.radii = radii\n",
    "\n",
    "regions_peak_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "\n",
    "# Create dummy data\n",
    "regions_dict = {'Chromosome': ['chr1', 'chr1'],\n",
    "                    'Start': [10000, 30000],\n",
    "                    'End': [10300, 31200]}\n",
    "\n",
    "regions_pr = pr.from_dict(regions_dict)\n",
    "\n",
    "# Write to tmp bed file\n",
    "regions_pr.to_bed(regions_peak_file.name)\n",
    "regions_peak_file.flush()\n",
    "\n",
    "conversionObject = RegionConversion(model.dataset.regions, regions_peak_file.name)\n",
    "\n",
    "# print(accessibility_peak_matrix.shape)\n",
    "matrix, indices = conversionObject.get_binary_vector(vector = accessibility_peak_matrix[0,:])\n",
    "gen = load_data_runtime(data=model.dataset.get_data(Dataset.ALL),\n",
    "         label_cell_types=model.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "         eval_cell_types=model.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "         matrix=model.dataset.matrix,\n",
    "         targetmap=model.dataset.targetmap,\n",
    "         cellmap=model.dataset.cellmap,\n",
    "         radii = model.radii,\n",
    "         mode = Dataset.RUNTIME,\n",
    "         similarity_matrix = matrix,\n",
    "         similarity_targets = ['DNase'],\n",
    "         indices = indices,\n",
    "         return_feature_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_to_list = np.array(list(gen()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accessibility_peak_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
       "| Chromosome   |     Start |       End |       idx |   Start_base |   End_base |   idx_base |\n",
       "| (category)   |   (int64) |   (int64) |   (int64) |      (int64) |    (int64) |    (int64) |\n",
       "|--------------+-----------+-----------+-----------+--------------+------------+------------|\n",
       "| chr1         |     10000 |     10300 |         0 |        10000 |      10200 |          0 |\n",
       "| chr1         |     10000 |     10300 |         0 |        10200 |      10400 |          1 |\n",
       "| chr1         |     30000 |     31200 |         1 |        30600 |      30800 |          6 |\n",
       "| chr1         |     30000 |     31200 |         1 |        30800 |      31000 |          7 |\n",
       "| chr1         |     30000 |     31200 |         1 |        31000 |      31200 |          8 |\n",
       "+--------------+-----------+-----------+-----------+--------------+------------+------------+\n",
       "Unstranded PyRanges object has 5 rows and 7 columns from 1 chromosomes.\n",
       "For printing, the PyRanges was sorted on Chromosome."
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversionObject.joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 6, 7, 8])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "same_size = accessibility_peak_matrix.shape[1] == len(conversionObject.joined.idx_base)\n",
    "\n",
    "if not same_size:\n",
    "    added_indices = []\n",
    "    old_idx, counter, old_i = 0, 0, 0\n",
    "    indices_to_merge = []\n",
    "    for ctr, (i, i_base) in enumerate(zip(conversionObject.joined.idx, conversionObject.joined.idx_base)):\n",
    "        if i_base == -1:\n",
    "            continue\n",
    "        if i != old_i:\n",
    "            indices_to_merge.append((old_idx, counter))\n",
    "            old_idx = counter\n",
    "        added_indices.append(accessibility_peak_matrix[:, i])\n",
    "        counter += 1\n",
    "        old_i = i\n",
    "    indices_to_merge.append((old_idx, len(conversionObject.joined.idx)))\n",
    "\n",
    "    a = np.stack(added_indices)\n",
    "else:\n",
    "    a = np.transpose(accessibility_peak_matrix, axes=[1, 0])\n",
    "\n",
    "print(a)\n",
    "print(gen_to_list.shape)\n",
    "\n",
    "a = a[:, None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 4)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_to_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1, 8)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4) (5, 1, 8)\n",
      "> \u001b[0;32m/home/eecs/rvkoodli/epitome_modified/epitome/functions.py\u001b[0m(226)\u001b[0;36mcompute_casv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    224 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    225 \u001b[0;31m        \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 226 \u001b[0;31m        \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    227 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    228 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "out = compute_casv(gen_to_list, a, model.radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 4, 8)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n"
     ]
    }
   ],
   "source": [
    "orig_gen = load_data(model.dataset.get_data(Dataset.ALL),\n",
    "                 model.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 model.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 model.dataset.matrix,\n",
    "                 model.dataset.targetmap,\n",
    "                 model.dataset.cellmap,\n",
    "                 radii = model.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = model.dataset.similarity_targets,\n",
    "                 indices = indices,\n",
    "                 return_feature_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-225-6785598b8898>\u001b[0m(168)\u001b[0;36mg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    166 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m                \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 168 \u001b[0;31m                \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  \n",
      "ipdb>  \n",
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-225-6785598b8898>\u001b[0m(168)\u001b[0;36mg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    166 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m                \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 168 \u001b[0;31m                \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-225-6785598b8898>\u001b[0m(168)\u001b[0;36mg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    166 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m                \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 168 \u001b[0;31m                \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-225-6785598b8898>\u001b[0m(168)\u001b[0;36mg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    166 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m                \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 168 \u001b[0;31m                \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-225-6785598b8898>\u001b[0m(168)\u001b[0;36mg\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    166 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    167 \u001b[0;31m                \u001b[0;31m# get indices for each radius in radii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 168 \u001b[0;31m                \u001b[0mradius_ranges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_radius_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    169 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    170 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius_ranges\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "orig_list = list(orig_gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8587562,), array([0, 1, 6, 7, 8]))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8587562)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dataset.get_data(Dataset.ALL).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orig_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(orig_list[4][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 12)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(map(lambda x: x[0][0], orig_list))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HepG2_DNase' 'HepG2_CTCF' 'HepG2_r1_agree' 'HeLa-S3_DNase'\n",
      " 'HeLa-S3_CTCF' 'HeLa-S3_r1_agree' 'H1_DNase' 'H1_CTCF' 'H1_r1_agree'\n",
      " 'A549_DNase' 'A549_CTCF' 'A549_r1_agree']\n"
     ]
    }
   ],
   "source": [
    "print(orig_list[1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0 \t HepG2_DNase\n",
      " 0.0 \t HepG2_CTCF\n",
      " 0.0 \t HepG2_r1_agree\n",
      " 0.0 \t HeLa-S3_DNase\n",
      " 0.0 \t HeLa-S3_CTCF\n",
      " 0.0 \t HeLa-S3_r1_agree\n",
      " 0.0 \t H1_DNase\n",
      " 0.0 \t H1_CTCF\n",
      " 0.0 \t H1_r1_agree\n",
      " 0.0 \t A549_DNase\n",
      " 0.0 \t A549_CTCF\n",
      " 0.0 \t A549_r1_agree\n"
     ]
    }
   ],
   "source": [
    "for (i, j) in zip(orig_list[2][0][0], orig_list[2][1][0]):\n",
    "    print(\"\", i, '\\t', j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 4, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_stack' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-0a62db7b6e50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mto_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'to_stack' is not defined"
     ]
    }
   ],
   "source": [
    "to_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using ['PLACEHOLDER_CELL'] as labels for mode Dataset.RUNTIME\n"
     ]
    }
   ],
   "source": [
    "to_stack = load_data_no_label_mask(model.dataset.get_data(Dataset.ALL),\n",
    "                 model.test_celltypes,   # used for labels. Should be all for train/eval and subset for test\n",
    "                 model.eval_cell_types,   # used for rotating features. Should be all - test for train/eval\n",
    "                 model.dataset.matrix,\n",
    "                 model.dataset.targetmap,\n",
    "                 model.dataset.cellmap,\n",
    "                 radii = model.radii,\n",
    "                 mode = Dataset.RUNTIME,\n",
    "                 similarity_matrix = matrix,\n",
    "                 similarity_targets = model.dataset.similarity_targets,\n",
    "                 indices = indices,\n",
    "                 return_feature_names = True)\n",
    "\n",
    "to_stack = list(to_stack())\n",
    "stacked = np.stack([to_stack] * accessibility_peak_matrix.shape[0], axis=0)\n",
    "names = stacked[:, :, 1]\n",
    "to_stack = stacked[:, :, 0]\n",
    "to_stack = np.expand_dims(to_stack, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5, 1)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_stack[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
